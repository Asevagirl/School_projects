{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import Ridge  \n",
    "from sklearn.linear_model import Lasso  \n",
    "from sklearn.svm import SVR \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "np.set_printoptions(precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables et dimesionnalité\n",
    "nb_AD = 28\n",
    "nb_MCI = 22\n",
    "nb_SCI = 22\n",
    "Freqs= ['ALPHA', 'BETA', 'DELTA', 'THETA']\n",
    "Seuils = [100, 70, 50, 30, 20, 10]\n",
    "dataFolder = 'EpEn data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chargement des matricces des trois types des patients\n",
    "x_AD = []\n",
    "for i in range(1, nb_AD+1):\n",
    "    x = {}\n",
    "    for freq in Freqs:\n",
    "        x[freq + '_100'] = loadmat(dataFolder + freq + '/' \n",
    "                                    + 'AD' + '/' \n",
    "                                    + str(i) + '.mat')[freq]\n",
    "    x_AD.append(x)\n",
    "\n",
    "x_MCI = []\n",
    "for i in range(1, nb_MCI+1):\n",
    "    x = {}\n",
    "    for freq in Freqs:\n",
    "        x[freq + '_100'] = loadmat(dataFolder + freq + '/' \n",
    "                                    + 'MCI' + '/' \n",
    "                                    + str(i) + '.mat')[freq]\n",
    "    x_MCI.append(x)\n",
    "\n",
    "x_SCI= []\n",
    "for i in range(1, nb_SCI+1):\n",
    "    x = {}\n",
    "    for freq in Freqs:\n",
    "        x[freq + '_100'] = loadmat(dataFolder + freq + '/' \n",
    "                                    + 'SCI' + '/' \n",
    "                                    + str(i) + '.mat')[freq]\n",
    "    x_SCI.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On étend les dictionaires aux 6 différents niveau de seuil\n",
    "def get_percentile(x, seuil):\n",
    "    y = x.copy()\n",
    "    percentile_limit = np.percentile(x, 100 - seuil)\n",
    "    y[y<percentile_limit] = 0\n",
    "    return y\n",
    "\n",
    "\n",
    "for i in range(nb_AD):\n",
    "    for freq in Freqs:\n",
    "        for seuil in Seuils:\n",
    "            x_AD[i][freq+'_'+str(seuil)] = get_percentile(x_AD[i][str(freq)+'_100'], seuil)\n",
    "            \n",
    "for i in range(nb_MCI):\n",
    "    for freq in Freqs:\n",
    "        for seuil in Seuils:\n",
    "            x_MCI[i][freq+'_'+str(seuil)] = get_percentile(x_MCI[i][str(freq)+'_100'], seuil)\n",
    "            \n",
    "for i in range(nb_SCI):\n",
    "    for freq in Freqs:\n",
    "        for seuil in Seuils:\n",
    "            x_SCI[i][freq+'_'+str(seuil)] = get_percentile(x_SCI[i][str(freq)+'_100'], seuil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x125ae78d0>"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(x_AD[27]['ALPHA_10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_connexions_electrode(array):\n",
    "    connexions = []\n",
    "    for i in range(array.shape[0]):\n",
    "        connexion = 0\n",
    "        for j in range(len(connexions)):\n",
    "            if array[i, j]>0:\n",
    "                connexion += 1\n",
    "        connexions.append(connexion)\n",
    "    return connexions\n",
    "\n",
    "\n",
    "def variance_cdf(array):\n",
    "    variance_list = []\n",
    "    for i in range(array.shape[0]):\n",
    "        cdf = np.cumsum(array[i, :])\n",
    "        variance_list.append(np.var(cdf))\n",
    "    return variance_list\n",
    "\n",
    "def moyenne(array):\n",
    "    moyennes = []\n",
    "    for i in range(array.shape[0]):\n",
    "        moyenne = array[i, :].mean()\n",
    "        moyennes.append(moyenne)\n",
    "    return moyennes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "Var=[]\n",
    "for freq in Freqs:\n",
    "    for seuil in Seuils:\n",
    "        Var.append(freq+'_'+str(seuil))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices_AD = {}\n",
    "for var in Var:\n",
    "    matrice=[]\n",
    "    for i in range (len(x_AD)):\n",
    "        t = moyenne(x_AD[i][var])\n",
    "        matrice.append(t)\n",
    "    matrices_AD[var]= matrice\n",
    "    \n",
    "matrices_MCI = {}\n",
    "for var in Var:\n",
    "    matrice=[]\n",
    "    for i in range (len(x_MCI)):\n",
    "        t = moyenne(x_MCI[i][var])\n",
    "        matrice.append(t)\n",
    "    matrices_MCI[var]= matrice\n",
    "    \n",
    "\n",
    "matrices_SCI = {}\n",
    "for var in Var:\n",
    "    matrice=[]\n",
    "    for i in range (len(x_SCI)):\n",
    "        t = moyenne(x_SCI[i][var])\n",
    "        matrice.append(t)\n",
    "    matrices_SCI[var]= matrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "Elec = ['Elec1', 'Elec2', 'Elec3', 'Elec4', 'Elec5', 'Elec6', 'Elec7', 'Elec8', 'Elec9', 'Elec10', 'Elec11', 'Elec12', 'Elec13', 'Elec14', 'Elec15', 'Elec16', 'Elec17', 'Elec18', 'Elec19', 'Elec20', 'Elec21', 'Elec22', 'Elec23', 'Elec24', 'Elec25', 'Elec26', 'Elec27', 'Elec28', 'Elec29', 'Elec30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_creator(array,names):\n",
    "    x = pd.DataFrame(array,columns=names)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_AD_ALPHA_100= dataframe_creator(matrices_AD['ALPHA_100'],Elec)\n",
    "data_AD_ALPHA_70= dataframe_creator(matrices_AD['ALPHA_70'],Elec)\n",
    "data_AD_ALPHA_50= dataframe_creator(matrices_AD['ALPHA_50'],Elec)\n",
    "data_AD_ALPHA_30= dataframe_creator(matrices_AD['ALPHA_30'],Elec)\n",
    "data_AD_ALPHA_20= dataframe_creator(matrices_AD['ALPHA_20'],Elec)\n",
    "data_AD_ALPHA_10= dataframe_creator(matrices_AD['ALPHA_10'],Elec)\n",
    "data_AD_BETA_100= dataframe_creator(matrices_AD['BETA_100'],Elec)\n",
    "data_AD_BETA_70= dataframe_creator(matrices_AD['BETA_70'],Elec)\n",
    "data_AD_BETA_50= dataframe_creator(matrices_AD['BETA_50'],Elec)\n",
    "data_AD_BETA_30= dataframe_creator(matrices_AD['BETA_30'],Elec)\n",
    "data_AD_BETA_20= dataframe_creator(matrices_AD['BETA_20'],Elec)\n",
    "data_AD_BETA_10= dataframe_creator(matrices_AD['BETA_10'],Elec)\n",
    "data_AD_DELTA_100= dataframe_creator(matrices_AD['DELTA_100'],Elec)\n",
    "data_AD_DELTA_70= dataframe_creator(matrices_AD['DELTA_70'],Elec)\n",
    "data_AD_DELTA_50= dataframe_creator(matrices_AD['DELTA_50'],Elec)\n",
    "data_AD_DELTA_30= dataframe_creator(matrices_AD['DELTA_30'],Elec)\n",
    "data_AD_DELTA_20= dataframe_creator(matrices_AD['DELTA_20'],Elec)\n",
    "data_AD_DELTA_10= dataframe_creator(matrices_AD['DELTA_10'],Elec)\n",
    "data_AD_THETA_100= dataframe_creator(matrices_AD['THETA_100'],Elec)\n",
    "data_AD_THETA_70= dataframe_creator(matrices_AD['THETA_70'],Elec)\n",
    "data_AD_THETA_50= dataframe_creator(matrices_AD['THETA_50'],Elec)\n",
    "data_AD_THETA_30= dataframe_creator(matrices_AD['THETA_30'],Elec)\n",
    "data_AD_THETA_20= dataframe_creator(matrices_AD['THETA_20'],Elec)\n",
    "data_AD_THETA_10= dataframe_creator(matrices_AD['THETA_10'],Elec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_MCI_ALPHA_100= dataframe_creator(matrices_MCI['ALPHA_100'],Elec)\n",
    "data_MCI_ALPHA_70= dataframe_creator(matrices_MCI['ALPHA_70'],Elec)\n",
    "data_MCI_ALPHA_50= dataframe_creator(matrices_MCI['ALPHA_50'],Elec)\n",
    "data_MCI_ALPHA_30= dataframe_creator(matrices_MCI['ALPHA_30'],Elec)\n",
    "data_MCI_ALPHA_20= dataframe_creator(matrices_MCI['ALPHA_20'],Elec)\n",
    "data_MCI_ALPHA_10= dataframe_creator(matrices_MCI['ALPHA_10'],Elec)\n",
    "data_MCI_BETA_100= dataframe_creator(matrices_MCI['BETA_100'],Elec)\n",
    "data_MCI_BETA_70= dataframe_creator(matrices_MCI['BETA_70'],Elec)\n",
    "data_MCI_BETA_50= dataframe_creator(matrices_MCI['BETA_50'],Elec)\n",
    "data_MCI_BETA_30= dataframe_creator(matrices_MCI['BETA_30'],Elec)\n",
    "data_MCI_BETA_20= dataframe_creator(matrices_MCI['BETA_20'],Elec)\n",
    "data_MCI_BETA_10= dataframe_creator(matrices_MCI['BETA_10'],Elec)\n",
    "data_MCI_DELTA_100= dataframe_creator(matrices_MCI['DELTA_100'],Elec)\n",
    "data_MCI_DELTA_70= dataframe_creator(matrices_MCI['DELTA_70'],Elec)\n",
    "data_MCI_DELTA_50= dataframe_creator(matrices_MCI['DELTA_50'],Elec)\n",
    "data_MCI_DELTA_30= dataframe_creator(matrices_MCI['DELTA_30'],Elec)\n",
    "data_MCI_DELTA_20= dataframe_creator(matrices_MCI['DELTA_20'],Elec)\n",
    "data_MCI_DELTA_10= dataframe_creator(matrices_MCI['DELTA_10'],Elec)\n",
    "data_MCI_THETA_100= dataframe_creator(matrices_MCI['THETA_100'],Elec)\n",
    "data_MCI_THETA_70= dataframe_creator(matrices_MCI['THETA_70'],Elec)\n",
    "data_MCI_THETA_50= dataframe_creator(matrices_MCI['THETA_50'],Elec)\n",
    "data_MCI_THETA_30= dataframe_creator(matrices_MCI['THETA_30'],Elec)\n",
    "data_MCI_THETA_20= dataframe_creator(matrices_MCI['THETA_20'],Elec)\n",
    "data_MCI_THETA_10= dataframe_creator(matrices_MCI['THETA_10'],Elec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_SCI_ALPHA_100= dataframe_creator(matrices_SCI['ALPHA_100'],Elec)\n",
    "data_SCI_ALPHA_70= dataframe_creator(matrices_SCI['ALPHA_70'],Elec)\n",
    "data_SCI_ALPHA_50= dataframe_creator(matrices_SCI['ALPHA_50'],Elec)\n",
    "data_SCI_ALPHA_30= dataframe_creator(matrices_SCI['ALPHA_30'],Elec)\n",
    "data_SCI_ALPHA_20= dataframe_creator(matrices_SCI['ALPHA_20'],Elec)\n",
    "data_SCI_ALPHA_10= dataframe_creator(matrices_SCI['ALPHA_10'],Elec)\n",
    "data_SCI_BETA_100= dataframe_creator(matrices_SCI['BETA_100'],Elec)\n",
    "data_SCI_BETA_70= dataframe_creator(matrices_SCI['BETA_70'],Elec)\n",
    "data_SCI_BETA_50= dataframe_creator(matrices_SCI['BETA_50'],Elec)\n",
    "data_SCI_BETA_30= dataframe_creator(matrices_SCI['BETA_30'],Elec)\n",
    "data_SCI_BETA_20= dataframe_creator(matrices_SCI['BETA_20'],Elec)\n",
    "data_SCI_BETA_10= dataframe_creator(matrices_SCI['BETA_10'],Elec)\n",
    "data_SCI_DELTA_100= dataframe_creator(matrices_SCI['DELTA_100'],Elec)\n",
    "data_SCI_DELTA_70= dataframe_creator(matrices_SCI['DELTA_70'],Elec)\n",
    "data_SCI_DELTA_50= dataframe_creator(matrices_SCI['DELTA_50'],Elec)\n",
    "data_SCI_DELTA_30= dataframe_creator(matrices_SCI['DELTA_30'],Elec)\n",
    "data_SCI_DELTA_20= dataframe_creator(matrices_SCI['DELTA_20'],Elec)\n",
    "data_SCI_DELTA_10= dataframe_creator(matrices_SCI['DELTA_10'],Elec)\n",
    "data_SCI_THETA_100= dataframe_creator(matrices_SCI['THETA_100'],Elec)\n",
    "data_SCI_THETA_70= dataframe_creator(matrices_SCI['THETA_70'],Elec)\n",
    "data_SCI_THETA_50= dataframe_creator(matrices_SCI['THETA_50'],Elec)\n",
    "data_SCI_THETA_30= dataframe_creator(matrices_SCI['THETA_30'],Elec)\n",
    "data_SCI_THETA_20= dataframe_creator(matrices_SCI['THETA_20'],Elec)\n",
    "data_SCI_THETA_10= dataframe_creator(matrices_SCI['THETA_10'],Elec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets AD vs MCI\n",
    "data_AD_MCI_ALPHA_100= pd.concat([data_AD_ALPHA_100,data_MCI_ALPHA_100])\n",
    "data_AD_MCI_ALPHA_70= pd.concat([data_AD_ALPHA_70,data_MCI_ALPHA_70])\n",
    "data_AD_MCI_ALPHA_50= pd.concat([data_AD_ALPHA_50,data_MCI_ALPHA_50])\n",
    "data_AD_MCI_ALPHA_30= pd.concat([data_AD_ALPHA_30,data_MCI_ALPHA_30])\n",
    "data_AD_MCI_ALPHA_20= pd.concat([data_AD_ALPHA_20,data_MCI_ALPHA_20])\n",
    "data_AD_MCI_ALPHA_10= pd.concat([data_AD_ALPHA_10,data_MCI_ALPHA_10])\n",
    "data_AD_MCI_BETA_100= pd.concat([data_AD_BETA_100,data_MCI_BETA_100])\n",
    "data_AD_MCI_BETA_70= pd.concat([data_AD_BETA_70,data_MCI_BETA_70])\n",
    "data_AD_MCI_BETA_50= pd.concat([data_AD_BETA_50,data_MCI_BETA_50])\n",
    "data_AD_MCI_BETA_30= pd.concat([data_AD_BETA_30,data_MCI_BETA_30])\n",
    "data_AD_MCI_BETA_20= pd.concat([data_AD_BETA_20,data_MCI_BETA_20])\n",
    "data_AD_MCI_BETA_10= pd.concat([data_AD_BETA_10,data_MCI_BETA_10])\n",
    "data_AD_MCI_DELTA_100= pd.concat([data_AD_DELTA_100,data_MCI_DELTA_100])\n",
    "data_AD_MCI_DELTA_70= pd.concat([data_AD_DELTA_70,data_MCI_DELTA_70])\n",
    "data_AD_MCI_DELTA_50= pd.concat([data_AD_DELTA_50,data_MCI_DELTA_50])\n",
    "data_AD_MCI_DELTA_30= pd.concat([data_AD_DELTA_30,data_MCI_DELTA_30])\n",
    "data_AD_MCI_DELTA_20= pd.concat([data_AD_DELTA_20,data_MCI_DELTA_20])\n",
    "data_AD_MCI_DELTA_10= pd.concat([data_AD_DELTA_10,data_MCI_DELTA_10])\n",
    "data_AD_MCI_THETA_100= pd.concat([data_AD_THETA_100,data_MCI_THETA_100])\n",
    "data_AD_MCI_THETA_70= pd.concat([data_AD_THETA_70,data_MCI_THETA_70])\n",
    "data_AD_MCI_THETA_50= pd.concat([data_AD_THETA_50,data_MCI_THETA_50])\n",
    "data_AD_MCI_THETA_30= pd.concat([data_AD_THETA_30,data_MCI_THETA_30])\n",
    "data_AD_MCI_THETA_20= pd.concat([data_AD_THETA_20,data_MCI_THETA_20])\n",
    "data_AD_MCI_THETA_10= pd.concat([data_AD_THETA_10,data_MCI_THETA_10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets SCI vs MCI\n",
    "data_SCI_MCI_ALPHA_100= pd.concat([data_SCI_ALPHA_100,data_MCI_ALPHA_100])\n",
    "data_SCI_MCI_ALPHA_70= pd.concat([data_SCI_ALPHA_70,data_MCI_ALPHA_70])\n",
    "data_SCI_MCI_ALPHA_50= pd.concat([data_SCI_ALPHA_50,data_MCI_ALPHA_50])\n",
    "data_SCI_MCI_ALPHA_30= pd.concat([data_SCI_ALPHA_30,data_MCI_ALPHA_30])\n",
    "data_SCI_MCI_ALPHA_20= pd.concat([data_SCI_ALPHA_20,data_MCI_ALPHA_20])\n",
    "data_SCI_MCI_ALPHA_10= pd.concat([data_SCI_ALPHA_10,data_MCI_ALPHA_10])\n",
    "data_SCI_MCI_BETA_100= pd.concat([data_SCI_BETA_100,data_MCI_BETA_100])\n",
    "data_SCI_MCI_BETA_70= pd.concat([data_SCI_BETA_70,data_MCI_BETA_70])\n",
    "data_SCI_MCI_BETA_50= pd.concat([data_SCI_BETA_50,data_MCI_BETA_50])\n",
    "data_SCI_MCI_BETA_30= pd.concat([data_SCI_BETA_30,data_MCI_BETA_30])\n",
    "data_SCI_MCI_BETA_20= pd.concat([data_SCI_BETA_20,data_MCI_BETA_20])\n",
    "data_SCI_MCI_BETA_10= pd.concat([data_SCI_BETA_10,data_MCI_BETA_10])\n",
    "data_SCI_MCI_DELTA_100= pd.concat([data_SCI_DELTA_100,data_MCI_DELTA_100])\n",
    "data_SCI_MCI_DELTA_70= pd.concat([data_SCI_DELTA_70,data_MCI_DELTA_70])\n",
    "data_SCI_MCI_DELTA_50= pd.concat([data_SCI_DELTA_50,data_MCI_DELTA_50])\n",
    "data_SCI_MCI_DELTA_30= pd.concat([data_SCI_DELTA_30,data_MCI_DELTA_30])\n",
    "data_SCI_MCI_DELTA_20= pd.concat([data_SCI_DELTA_20,data_MCI_DELTA_20])\n",
    "data_SCI_MCI_DELTA_10= pd.concat([data_SCI_DELTA_10,data_MCI_DELTA_10])\n",
    "data_SCI_MCI_THETA_100= pd.concat([data_SCI_THETA_100,data_MCI_THETA_100])\n",
    "data_SCI_MCI_THETA_70= pd.concat([data_SCI_THETA_70,data_MCI_THETA_70])\n",
    "data_SCI_MCI_THETA_50= pd.concat([data_SCI_THETA_50,data_MCI_THETA_50])\n",
    "data_SCI_MCI_THETA_30= pd.concat([data_SCI_THETA_30,data_MCI_THETA_30])\n",
    "data_SCI_MCI_THETA_20= pd.concat([data_SCI_THETA_20,data_MCI_THETA_20])\n",
    "data_SCI_MCI_THETA_10= pd.concat([data_SCI_THETA_10,data_MCI_THETA_10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "#datasets SCI vs AD\n",
    "data_SCI_AD_ALPHA_100= pd.concat([data_SCI_ALPHA_100,data_AD_ALPHA_100])\n",
    "data_SCI_AD_ALPHA_70= pd.concat([data_SCI_ALPHA_70,data_AD_ALPHA_70])\n",
    "data_SCI_AD_ALPHA_50= pd.concat([data_SCI_ALPHA_50,data_AD_ALPHA_50])\n",
    "data_SCI_AD_ALPHA_30= pd.concat([data_SCI_ALPHA_30,data_AD_ALPHA_30])\n",
    "data_SCI_AD_ALPHA_20= pd.concat([data_SCI_ALPHA_20,data_AD_ALPHA_20])\n",
    "data_SCI_AD_ALPHA_10= pd.concat([data_SCI_ALPHA_10,data_AD_ALPHA_10])\n",
    "data_SCI_AD_BETA_100= pd.concat([data_SCI_BETA_100,data_AD_BETA_100])\n",
    "data_SCI_AD_BETA_70= pd.concat([data_SCI_BETA_70,data_AD_BETA_70])\n",
    "data_SCI_AD_BETA_50= pd.concat([data_SCI_BETA_50,data_AD_BETA_50])\n",
    "data_SCI_AD_BETA_30= pd.concat([data_SCI_BETA_30,data_AD_BETA_30])\n",
    "data_SCI_AD_BETA_20= pd.concat([data_SCI_BETA_20,data_AD_BETA_20])\n",
    "data_SCI_AD_BETA_10= pd.concat([data_SCI_BETA_10,data_AD_BETA_10])\n",
    "data_SCI_AD_DELTA_100= pd.concat([data_SCI_DELTA_100,data_AD_DELTA_100])\n",
    "data_SCI_AD_DELTA_70= pd.concat([data_SCI_DELTA_70,data_AD_DELTA_70])\n",
    "data_SCI_AD_DELTA_50= pd.concat([data_SCI_DELTA_50,data_AD_DELTA_50])\n",
    "data_SCI_AD_DELTA_30= pd.concat([data_SCI_DELTA_30,data_AD_DELTA_30])\n",
    "data_SCI_AD_DELTA_20= pd.concat([data_SCI_DELTA_20,data_AD_DELTA_20])\n",
    "data_SCI_AD_DELTA_10= pd.concat([data_SCI_DELTA_10,data_AD_DELTA_10])\n",
    "data_SCI_AD_THETA_100= pd.concat([data_SCI_THETA_100,data_AD_THETA_100])\n",
    "data_SCI_AD_THETA_70= pd.concat([data_SCI_THETA_70,data_AD_THETA_70])\n",
    "data_SCI_AD_THETA_50= pd.concat([data_SCI_THETA_50,data_AD_THETA_50])\n",
    "data_SCI_AD_THETA_30= pd.concat([data_SCI_THETA_30,data_AD_THETA_30])\n",
    "data_SCI_AD_THETA_20= pd.concat([data_SCI_THETA_20,data_AD_THETA_20])\n",
    "data_SCI_AD_THETA_10= pd.concat([data_SCI_THETA_10,data_AD_THETA_10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 30)"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_SCI_AD_THETA_10.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selection de variables (Stepwise)\n",
    "\n",
    "def stepwise_selection(X, y, initial_list=[], threshold_in=0.01, threshold_out = 0.05, ):\n",
    "    included = list(initial_list)\n",
    "    while True:\n",
    "        changed=False\n",
    "        excluded = list(set(X.columns)-set(included))\n",
    "        new_pval = pd.Series(index=excluded)\n",
    "        for new_column in excluded:\n",
    "            model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included+[new_column]]))).fit()\n",
    "            new_pval[new_column] = model.pvalues[new_column]\n",
    "        best_pval = new_pval.min()\n",
    "        if best_pval < threshold_in:\n",
    "            best_feature = new_pval.argmin()\n",
    "            included.append(best_feature)\n",
    "            changed=True\n",
    "\n",
    "        # backward step\n",
    "        model = sm.OLS(y, sm.add_constant(pd.DataFrame(X[included]))).fit()\n",
    "        # use all coefs except intercept\n",
    "        pvalues = model.pvalues.iloc[1:]\n",
    "        worst_pval = pvalues.max() # null if pvalues is empty\n",
    "        if worst_pval > threshold_out:\n",
    "            changed=True\n",
    "            worst_feature = pvalues.argmax()\n",
    "            included.remove(worst_feature)\n",
    "        if not changed:\n",
    "            break\n",
    "    return included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélaction 1 : AD vs MCI\n",
    "varaibles1 = stepwise_selection(data_AD_MCI_ALPHA_100, [0]*28+[1]*22)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False).fit(data_AD_MCI_ALPHA_100, [0]*28+[1]*22)\n",
    "model = SelectFromModel(lsvc, prefit=True)\n",
    "\n",
    "selected_feat= data_AD_MCI_ALPHA_100.columns[(model.get_support())]\n",
    "print(selected_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 0)"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = model.transform(data_AD_MCI_ALPHA_100)\n",
    "X_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avec randomforest classifer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.ensemble \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sklearn.ensemble.RandomForestClassifier(max_depth=2, random_state=0)\n",
    "model.fit(data_AD_MCI_ALPHA_100, [0]*28+[1]*22)\n",
    "sel = SelectFromModel(model)\n",
    "sel.fit(data_AD_MCI_ALPHA_100, [0]*28+[1]*22)\n",
    "\n",
    "selected_feat= data_AD_MCI_ALPHA_100.columns[(sel.get_support())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## avec extratreesclassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AD_MCI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 13, 28, 26, 1, 23, 2, 17, 22, 1, 30, 2, 11, 9, 15, 9, 9, 4, 11, 27, 27, 7, 7, 7]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "def max_feature(array):\n",
    "    ind = np.argmax(array)\n",
    "    var = 0\n",
    "    if(ind > 0):\n",
    "        return(var - 1)\n",
    "    else: \n",
    "        return(var)\n",
    "\n",
    "#liste des variables de la premiere phase de selection\n",
    "selected_var = []\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_AD_MCI_ALPHA_100, [0]*28+[1]*22, test_size=0.33, random_state=0)\n",
    "model1 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model1.fit(X_train, y_train)\n",
    "var1 = np.argmax(model2.feature_importances_)+1\n",
    "selected_var.append(var1)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_AD_MCI_ALPHA_10, [0]*28+[1]*22, test_size=0.33, random_state=0)\n",
    "model2 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model2.fit(X_train, y_train)\n",
    "var2 = np.argmax(model2.feature_importances_)+1\n",
    "selected_var.append(var2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_AD_MCI_ALPHA_20, [0]*28+[1]*22, test_size=0.33, random_state=0)\n",
    "model3 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model3.fit(X_train, y_train)\n",
    "var3 = np.argmax(model3.feature_importances_)+1\n",
    "selected_var.append(var3)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_AD_MCI_ALPHA_30, [0]*28+[1]*22, test_size=0.33, random_state=0)\n",
    "model4 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model4.fit(X_train, y_train)\n",
    "var4 = np.argmax(model4.feature_importances_)+1\n",
    "selected_var.append(var4)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_AD_MCI_ALPHA_50, [0]*28+[1]*22, test_size=0.33, random_state=0)\n",
    "model5 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model5.fit(X_train, y_train)\n",
    "var5 = np.argmax(model5.feature_importances_)\n",
    "selected_var.append(var5)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_AD_MCI_ALPHA_70, [0]*28+[1]*22, test_size=0.33, random_state=0)\n",
    "model6 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model6.fit(X_train, y_train)\n",
    "var6 = np.argmax(model6.feature_importances_)+1\n",
    "selected_var.append(var6)\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_AD_MCI_BETA_100, [0]*28+[1]*22, test_size=0.33, random_state=0)\n",
    "model7 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model7.fit(X_train, y_train)\n",
    "var7 = np.argmax(model7.feature_importances_)+1\n",
    "selected_var.append(var7)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_AD_MCI_BETA_10, [0]*28+[1]*22, test_size=0.33, random_state=0)\n",
    "model8 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model8.fit(X_train, y_train)\n",
    "var8 = np.argmax(model8.feature_importances_)+1\n",
    "selected_var.append(var8)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_AD_MCI_BETA_20, [0]*28+[1]*22, test_size=0.33, random_state=0)\n",
    "model9 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model9.fit(X_train, y_train)\n",
    "var9 = np.argmax(model9.feature_importances_)+1\n",
    "selected_var.append(var9)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_AD_MCI_BETA_30, [0]*28+[1]*22, test_size=0.33, random_state=0)\n",
    "model10 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model10.fit(X_train, y_train)\n",
    "var10 = np.argmax(model10.feature_importances_)+1\n",
    "selected_var.append(var10)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_AD_MCI_BETA_50, [0]*28+[1]*22, test_size=0.33, random_state=0)\n",
    "model11 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model11.fit(X_train, y_train)\n",
    "var11 = np.argmax(model11.feature_importances_)+1\n",
    "selected_var.append(var11)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_AD_MCI_BETA_70, [0]*28+[1]*22, test_size=0.33, random_state=0)\n",
    "model12 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model12.fit(X_train, y_train)\n",
    "var12 = np.argmax(model12.feature_importances_)+1\n",
    "selected_var.append(var12)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_AD_MCI_DELTA_100, [0]*28+[1]*22, test_size=0.33, random_state=0)\n",
    "model13 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model13.fit(X_train, y_train)\n",
    "var13 = np.argmax(model13.feature_importances_)+1\n",
    "selected_var.append(var13)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_AD_MCI_DELTA_10, [0]*28+[1]*22, test_size=0.33, random_state=0)\n",
    "model14 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model14.fit(X_train, y_train)\n",
    "var14 = np.argmax(model14.feature_importances_)+1\n",
    "selected_var.append(var14)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_AD_MCI_DELTA_20, [0]*28+[1]*22, test_size=0.33, random_state=0)\n",
    "model15 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model15.fit(X_train, y_train)\n",
    "var15 = np.argmax(model15.feature_importances_)+1\n",
    "selected_var.append(var15)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_AD_MCI_DELTA_30, [0]*28+[1]*22, test_size=0.33, random_state=0)\n",
    "model16 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model16.fit(X_train, y_train)\n",
    "var16 = np.argmax(model16.feature_importances_)+1\n",
    "selected_var.append(var16)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_AD_MCI_DELTA_50, [0]*28+[1]*22, test_size=0.33, random_state=0)\n",
    "model17 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model17.fit(X_train, y_train)\n",
    "var17 = np.argmax(model17.feature_importances_)+1\n",
    "selected_var.append(var17)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_AD_MCI_DELTA_70, [0]*28+[1]*22, test_size=0.33, random_state=0)\n",
    "model18 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model18.fit(X_train, y_train)\n",
    "var18 = np.argmax(model18.feature_importances_)+1\n",
    "selected_var.append(var18)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_AD_MCI_THETA_100, [0]*28+[1]*22, test_size=0.33, random_state=0)\n",
    "model19 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model19.fit(X_train, y_train)\n",
    "var19 = np.argmax(model19.feature_importances_)+1\n",
    "selected_var.append(var19)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_AD_MCI_THETA_10, [0]*28+[1]*22, test_size=0.33, random_state=0)\n",
    "model20 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model20.fit(X_train, y_train)\n",
    "var20 = np.argmax(model20.feature_importances_)+1\n",
    "selected_var.append(var20)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_AD_MCI_THETA_20, [0]*28+[1]*22, test_size=0.33, random_state=0)\n",
    "model21 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model21.fit(X_train, y_train)\n",
    "var21 = np.argmax(model21.feature_importances_)+1\n",
    "selected_var.append(var21)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_AD_MCI_THETA_30, [0]*28+[1]*22, test_size=0.33, random_state=0)\n",
    "model22 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model22.fit(X_train, y_train)\n",
    "var22 = np.argmax(model22.feature_importances_)+1\n",
    "selected_var.append(var22)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_AD_MCI_THETA_50, [0]*28+[1]*22, test_size=0.33, random_state=0)\n",
    "model23 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model23.fit(X_train, y_train)\n",
    "var23 = np.argmax(model23.feature_importances_)+1\n",
    "selected_var.append(var23)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_AD_MCI_THETA_70, [0]*28+[1]*22, test_size=0.33, random_state=0)\n",
    "model24 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model24.fit(X_train, y_train)\n",
    "var24 = np.argmax(model24.feature_importances_)+1\n",
    "selected_var.append(var24)\n",
    "\n",
    "#print(selected_var)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation d'une dataframe correspondante avec la variable selectionnee pour chaque cas de (freq,seuil)\n",
    "\n",
    "data_AD_MCI_ALPHA_100_new = dataframe_creator(data_AD_MCI_ALPHA_100['Elec'+str(var1)],['Elec'+str(var1)])\n",
    "data_AD_MCI_ALPHA_10_new = dataframe_creator(data_AD_MCI_ALPHA_10['Elec'+str(var2)],['Elec'+str(var2)])\n",
    "data_AD_MCI_ALPHA_20_new = dataframe_creator(data_AD_MCI_ALPHA_20['Elec'+str(var3)],['Elec'+str(var3)])\n",
    "data_AD_MCI_ALPHA_30_new = dataframe_creator(data_AD_MCI_ALPHA_30['Elec'+str(var4)],['Elec'+str(var4)])\n",
    "data_AD_MCI_ALPHA_50_new = dataframe_creator(data_AD_MCI_ALPHA_50['Elec'+str(var5)],['Elec'+str(var5)])\n",
    "data_AD_MCI_ALPHA_70_new = dataframe_creator(data_AD_MCI_ALPHA_70['Elec'+str(var6)],['Elec'+str(var6)])\n",
    "\n",
    "\n",
    "data_AD_MCI_BETA_100_new = dataframe_creator(data_AD_MCI_BETA_100['Elec'+str(var7)],['Elec'+str(var7)])\n",
    "data_AD_MCI_BETA_10_new = dataframe_creator(data_AD_MCI_BETA_10['Elec'+str(var8)],['Elec'+str(var8)])\n",
    "data_AD_MCI_BETA_20_new = dataframe_creator(data_AD_MCI_BETA_20['Elec'+str(var9)],['Elec'+str(var9)])\n",
    "data_AD_MCI_BETA_30_new = dataframe_creator(data_AD_MCI_BETA_30['Elec'+str(var10)],['Elec'+str(var10)])\n",
    "data_AD_MCI_BETA_50_new = dataframe_creator(data_AD_MCI_BETA_50['Elec'+str(var11)],['Elec'+str(var11)])\n",
    "data_AD_MCI_BETA_70_new = dataframe_creator(data_AD_MCI_BETA_70['Elec'+str(var12)],['Elec'+str(var12)])\n",
    "\n",
    "data_AD_MCI_DELTA_100_new = dataframe_creator(data_AD_MCI_DELTA_100['Elec'+str(var13)],['Elec'+str(var13)])\n",
    "data_AD_MCI_DELTA_10_new = dataframe_creator(data_AD_MCI_DELTA_10['Elec'+str(var14)],['Elec'+str(var14)])\n",
    "data_AD_MCI_DELTA_20_new = dataframe_creator(data_AD_MCI_DELTA_20['Elec'+str(var15)],['Elec'+str(var15)])\n",
    "data_AD_MCI_DELTA_30_new = dataframe_creator(data_AD_MCI_DELTA_30['Elec'+str(var16)],['Elec'+str(var16)])\n",
    "data_AD_MCI_DELTA_50_new = dataframe_creator(data_AD_MCI_DELTA_50['Elec'+str(var17)],['Elec'+str(var17)])\n",
    "data_AD_MCI_DELTA_70_new = dataframe_creator(data_AD_MCI_DELTA_70['Elec'+str(var18)],['Elec'+str(var18)])\n",
    "\n",
    "data_AD_MCI_THETA_100_new = dataframe_creator(data_AD_MCI_THETA_100['Elec'+str(var19)],['Elec'+str(var19)])\n",
    "data_AD_MCI_THETA_10_new = dataframe_creator(data_AD_MCI_THETA_10['Elec'+str(var20)],['Elec'+str(var20)])\n",
    "data_AD_MCI_THETA_20_new = dataframe_creator(data_AD_MCI_THETA_20['Elec'+str(var21)],['Elec'+str(var21)])\n",
    "data_AD_MCI_THETA_30_new = dataframe_creator(data_AD_MCI_THETA_30['Elec'+str(var22)],['Elec'+str(var22)])\n",
    "data_AD_MCI_THETA_50_new = dataframe_creator(data_AD_MCI_THETA_50['Elec'+str(var23)],['Elec'+str(var23)])\n",
    "data_AD_MCI_THETA_70_new = dataframe_creator(data_AD_MCI_THETA_70['Elec'+str(var24)],['Elec'+str(var2)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation d'une base de données avec les 24  variables selectionnees dans la premiere etape de selection\n",
    "datas_AD_MCI = [data_AD_MCI_ALPHA_100_new,data_AD_MCI_ALPHA_10_new,data_AD_MCI_ALPHA_20_new,data_AD_MCI_ALPHA_30_new,data_AD_MCI_ALPHA_50_new,data_AD_MCI_ALPHA_70_new,data_AD_MCI_BETA_100_new,data_AD_MCI_BETA_10_new,data_AD_MCI_BETA_20_new,data_AD_MCI_BETA_30_new,data_AD_MCI_BETA_50_new,data_AD_MCI_BETA_70_new,data_AD_MCI_DELTA_100_new,data_AD_MCI_DELTA_10_new,data_AD_MCI_DELTA_20_new,data_AD_MCI_DELTA_30_new,data_AD_MCI_DELTA_50_new,data_AD_MCI_DELTA_70_new,data_AD_MCI_THETA_100_new,data_AD_MCI_THETA_10_new,data_AD_MCI_THETA_20_new,data_AD_MCI_THETA_30_new,data_AD_MCI_THETA_50_new,data_AD_MCI_THETA_70_new]\n",
    "data_AD_MCI_selection1 = pd.concat((iDF for iDF in datas_AD_MCI),axis=1, join='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Elec13', 'Elec13', 'Elec28', 'Elec23', 'Elec13', 'Elec13', 'Elec13',\n",
      "       'Elec13', 'Elec13', 'Elec13'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elec13</th>\n",
       "      <th>Elec13</th>\n",
       "      <th>Elec28</th>\n",
       "      <th>Elec23</th>\n",
       "      <th>Elec13</th>\n",
       "      <th>Elec13</th>\n",
       "      <th>Elec13</th>\n",
       "      <th>Elec13</th>\n",
       "      <th>Elec13</th>\n",
       "      <th>Elec13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.577629</td>\n",
       "      <td>0.022112</td>\n",
       "      <td>0.197307</td>\n",
       "      <td>0.450812</td>\n",
       "      <td>0.022031</td>\n",
       "      <td>0.211105</td>\n",
       "      <td>0.330204</td>\n",
       "      <td>0.481370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.171078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.559443</td>\n",
       "      <td>0.044613</td>\n",
       "      <td>0.063940</td>\n",
       "      <td>0.478528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.134694</td>\n",
       "      <td>0.211634</td>\n",
       "      <td>0.578711</td>\n",
       "      <td>0.085965</td>\n",
       "      <td>0.275153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.580369</td>\n",
       "      <td>0.105130</td>\n",
       "      <td>0.168667</td>\n",
       "      <td>0.495886</td>\n",
       "      <td>0.074503</td>\n",
       "      <td>0.222271</td>\n",
       "      <td>0.320779</td>\n",
       "      <td>0.458076</td>\n",
       "      <td>0.044019</td>\n",
       "      <td>0.322039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.565693</td>\n",
       "      <td>0.022738</td>\n",
       "      <td>0.067315</td>\n",
       "      <td>0.222778</td>\n",
       "      <td>0.072687</td>\n",
       "      <td>0.234821</td>\n",
       "      <td>0.333539</td>\n",
       "      <td>0.511042</td>\n",
       "      <td>0.020971</td>\n",
       "      <td>0.185582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.554783</td>\n",
       "      <td>0.022106</td>\n",
       "      <td>0.235868</td>\n",
       "      <td>0.464825</td>\n",
       "      <td>0.037580</td>\n",
       "      <td>0.226030</td>\n",
       "      <td>0.310430</td>\n",
       "      <td>0.484789</td>\n",
       "      <td>0.063625</td>\n",
       "      <td>0.271823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.563122</td>\n",
       "      <td>0.022099</td>\n",
       "      <td>0.089261</td>\n",
       "      <td>0.367501</td>\n",
       "      <td>0.095056</td>\n",
       "      <td>0.278702</td>\n",
       "      <td>0.401454</td>\n",
       "      <td>0.433278</td>\n",
       "      <td>0.087195</td>\n",
       "      <td>0.340410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.563253</td>\n",
       "      <td>0.022067</td>\n",
       "      <td>0.083227</td>\n",
       "      <td>0.459194</td>\n",
       "      <td>0.038552</td>\n",
       "      <td>0.277262</td>\n",
       "      <td>0.317500</td>\n",
       "      <td>0.591007</td>\n",
       "      <td>0.042655</td>\n",
       "      <td>0.335736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.671194</td>\n",
       "      <td>0.024370</td>\n",
       "      <td>0.024192</td>\n",
       "      <td>0.376787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.234779</td>\n",
       "      <td>0.490576</td>\n",
       "      <td>0.189263</td>\n",
       "      <td>0.150065</td>\n",
       "      <td>0.450446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.586149</td>\n",
       "      <td>0.066671</td>\n",
       "      <td>0.257483</td>\n",
       "      <td>0.430835</td>\n",
       "      <td>0.018184</td>\n",
       "      <td>0.180920</td>\n",
       "      <td>0.248558</td>\n",
       "      <td>0.480367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.172383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.579051</td>\n",
       "      <td>0.067546</td>\n",
       "      <td>0.237269</td>\n",
       "      <td>0.555016</td>\n",
       "      <td>0.064144</td>\n",
       "      <td>0.286766</td>\n",
       "      <td>0.375275</td>\n",
       "      <td>0.493950</td>\n",
       "      <td>0.085978</td>\n",
       "      <td>0.503399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.606855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112776</td>\n",
       "      <td>0.530862</td>\n",
       "      <td>0.043565</td>\n",
       "      <td>0.204148</td>\n",
       "      <td>0.302097</td>\n",
       "      <td>0.247180</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.586252</td>\n",
       "      <td>0.130512</td>\n",
       "      <td>0.186763</td>\n",
       "      <td>0.430320</td>\n",
       "      <td>0.113892</td>\n",
       "      <td>0.280739</td>\n",
       "      <td>0.417009</td>\n",
       "      <td>0.555134</td>\n",
       "      <td>0.106215</td>\n",
       "      <td>0.354219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.570543</td>\n",
       "      <td>0.085980</td>\n",
       "      <td>0.084522</td>\n",
       "      <td>0.364421</td>\n",
       "      <td>0.036189</td>\n",
       "      <td>0.184371</td>\n",
       "      <td>0.358935</td>\n",
       "      <td>0.564878</td>\n",
       "      <td>0.214780</td>\n",
       "      <td>0.613309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.580475</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067292</td>\n",
       "      <td>0.416651</td>\n",
       "      <td>0.064399</td>\n",
       "      <td>0.247290</td>\n",
       "      <td>0.351717</td>\n",
       "      <td>0.271891</td>\n",
       "      <td>0.022143</td>\n",
       "      <td>0.215590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.602469</td>\n",
       "      <td>0.112858</td>\n",
       "      <td>0.195274</td>\n",
       "      <td>0.479619</td>\n",
       "      <td>0.069805</td>\n",
       "      <td>0.335571</td>\n",
       "      <td>0.419032</td>\n",
       "      <td>0.502037</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.213493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.570039</td>\n",
       "      <td>0.045900</td>\n",
       "      <td>0.155313</td>\n",
       "      <td>0.406251</td>\n",
       "      <td>0.037632</td>\n",
       "      <td>0.281599</td>\n",
       "      <td>0.336903</td>\n",
       "      <td>0.549891</td>\n",
       "      <td>0.088064</td>\n",
       "      <td>0.429423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.585510</td>\n",
       "      <td>0.045414</td>\n",
       "      <td>0.219907</td>\n",
       "      <td>0.482593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.202178</td>\n",
       "      <td>0.330515</td>\n",
       "      <td>0.408337</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.128008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.569974</td>\n",
       "      <td>0.045189</td>\n",
       "      <td>0.257916</td>\n",
       "      <td>0.449084</td>\n",
       "      <td>0.019336</td>\n",
       "      <td>0.251213</td>\n",
       "      <td>0.319750</td>\n",
       "      <td>0.529668</td>\n",
       "      <td>0.196494</td>\n",
       "      <td>0.405479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.564617</td>\n",
       "      <td>0.023085</td>\n",
       "      <td>0.151148</td>\n",
       "      <td>0.458802</td>\n",
       "      <td>0.068153</td>\n",
       "      <td>0.291989</td>\n",
       "      <td>0.377784</td>\n",
       "      <td>0.483817</td>\n",
       "      <td>0.109767</td>\n",
       "      <td>0.302689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.565474</td>\n",
       "      <td>0.045466</td>\n",
       "      <td>0.183215</td>\n",
       "      <td>0.401783</td>\n",
       "      <td>0.022575</td>\n",
       "      <td>0.228363</td>\n",
       "      <td>0.291789</td>\n",
       "      <td>0.425812</td>\n",
       "      <td>0.044453</td>\n",
       "      <td>0.432131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.581649</td>\n",
       "      <td>0.047800</td>\n",
       "      <td>0.115510</td>\n",
       "      <td>0.454538</td>\n",
       "      <td>0.088683</td>\n",
       "      <td>0.270246</td>\n",
       "      <td>0.397292</td>\n",
       "      <td>0.062598</td>\n",
       "      <td>0.022435</td>\n",
       "      <td>0.300389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.570040</td>\n",
       "      <td>0.065904</td>\n",
       "      <td>0.277162</td>\n",
       "      <td>0.440333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.113946</td>\n",
       "      <td>0.206032</td>\n",
       "      <td>0.512929</td>\n",
       "      <td>0.108348</td>\n",
       "      <td>0.295730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.537267</td>\n",
       "      <td>0.022024</td>\n",
       "      <td>0.088337</td>\n",
       "      <td>0.390925</td>\n",
       "      <td>0.025079</td>\n",
       "      <td>0.125919</td>\n",
       "      <td>0.298204</td>\n",
       "      <td>0.464825</td>\n",
       "      <td>0.065594</td>\n",
       "      <td>0.256344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.563113</td>\n",
       "      <td>0.022294</td>\n",
       "      <td>0.236636</td>\n",
       "      <td>0.410678</td>\n",
       "      <td>0.036721</td>\n",
       "      <td>0.248991</td>\n",
       "      <td>0.334765</td>\n",
       "      <td>0.536999</td>\n",
       "      <td>0.043248</td>\n",
       "      <td>0.169479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.557641</td>\n",
       "      <td>0.023499</td>\n",
       "      <td>0.149235</td>\n",
       "      <td>0.498261</td>\n",
       "      <td>0.021020</td>\n",
       "      <td>0.109088</td>\n",
       "      <td>0.211649</td>\n",
       "      <td>0.460806</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.171027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.569897</td>\n",
       "      <td>0.043927</td>\n",
       "      <td>0.064524</td>\n",
       "      <td>0.218277</td>\n",
       "      <td>0.060601</td>\n",
       "      <td>0.219519</td>\n",
       "      <td>0.293134</td>\n",
       "      <td>0.349785</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.557178</td>\n",
       "      <td>0.043556</td>\n",
       "      <td>0.126881</td>\n",
       "      <td>0.507864</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.092998</td>\n",
       "      <td>0.247769</td>\n",
       "      <td>0.477698</td>\n",
       "      <td>0.279952</td>\n",
       "      <td>0.532413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.557425</td>\n",
       "      <td>0.022322</td>\n",
       "      <td>0.127920</td>\n",
       "      <td>0.334561</td>\n",
       "      <td>0.062176</td>\n",
       "      <td>0.281481</td>\n",
       "      <td>0.378818</td>\n",
       "      <td>0.552960</td>\n",
       "      <td>0.021646</td>\n",
       "      <td>0.211587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.587911</td>\n",
       "      <td>0.023004</td>\n",
       "      <td>0.288044</td>\n",
       "      <td>0.533077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.159328</td>\n",
       "      <td>0.249935</td>\n",
       "      <td>0.551554</td>\n",
       "      <td>0.063261</td>\n",
       "      <td>0.396631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.589917</td>\n",
       "      <td>0.067485</td>\n",
       "      <td>0.257717</td>\n",
       "      <td>0.438865</td>\n",
       "      <td>0.060723</td>\n",
       "      <td>0.238011</td>\n",
       "      <td>0.356814</td>\n",
       "      <td>0.543100</td>\n",
       "      <td>0.043215</td>\n",
       "      <td>0.191025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.571514</td>\n",
       "      <td>0.065564</td>\n",
       "      <td>0.235282</td>\n",
       "      <td>0.523355</td>\n",
       "      <td>0.076210</td>\n",
       "      <td>0.275851</td>\n",
       "      <td>0.343841</td>\n",
       "      <td>0.540671</td>\n",
       "      <td>0.021431</td>\n",
       "      <td>0.252997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.550737</td>\n",
       "      <td>0.043059</td>\n",
       "      <td>0.106154</td>\n",
       "      <td>0.452051</td>\n",
       "      <td>0.019653</td>\n",
       "      <td>0.140408</td>\n",
       "      <td>0.237625</td>\n",
       "      <td>0.455313</td>\n",
       "      <td>0.131133</td>\n",
       "      <td>0.384062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.579386</td>\n",
       "      <td>0.109821</td>\n",
       "      <td>0.148567</td>\n",
       "      <td>0.438290</td>\n",
       "      <td>0.055013</td>\n",
       "      <td>0.254554</td>\n",
       "      <td>0.334215</td>\n",
       "      <td>0.560956</td>\n",
       "      <td>0.021746</td>\n",
       "      <td>0.230690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.568747</td>\n",
       "      <td>0.067465</td>\n",
       "      <td>0.062961</td>\n",
       "      <td>0.379157</td>\n",
       "      <td>0.059822</td>\n",
       "      <td>0.190411</td>\n",
       "      <td>0.243342</td>\n",
       "      <td>0.525273</td>\n",
       "      <td>0.021380</td>\n",
       "      <td>0.186924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.546917</td>\n",
       "      <td>0.021999</td>\n",
       "      <td>0.187181</td>\n",
       "      <td>0.407709</td>\n",
       "      <td>0.041091</td>\n",
       "      <td>0.205274</td>\n",
       "      <td>0.307977</td>\n",
       "      <td>0.555146</td>\n",
       "      <td>0.172619</td>\n",
       "      <td>0.424391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.571025</td>\n",
       "      <td>0.044762</td>\n",
       "      <td>0.232757</td>\n",
       "      <td>0.508099</td>\n",
       "      <td>0.038959</td>\n",
       "      <td>0.186135</td>\n",
       "      <td>0.253841</td>\n",
       "      <td>0.443868</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.562400</td>\n",
       "      <td>0.045367</td>\n",
       "      <td>0.283990</td>\n",
       "      <td>0.429595</td>\n",
       "      <td>0.062674</td>\n",
       "      <td>0.300304</td>\n",
       "      <td>0.405650</td>\n",
       "      <td>0.464101</td>\n",
       "      <td>0.064177</td>\n",
       "      <td>0.353759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.541559</td>\n",
       "      <td>0.044680</td>\n",
       "      <td>0.105221</td>\n",
       "      <td>0.458880</td>\n",
       "      <td>0.061094</td>\n",
       "      <td>0.247730</td>\n",
       "      <td>0.333738</td>\n",
       "      <td>0.533726</td>\n",
       "      <td>0.044835</td>\n",
       "      <td>0.426582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.564037</td>\n",
       "      <td>0.043939</td>\n",
       "      <td>0.241345</td>\n",
       "      <td>0.472884</td>\n",
       "      <td>0.035595</td>\n",
       "      <td>0.240809</td>\n",
       "      <td>0.322133</td>\n",
       "      <td>0.549960</td>\n",
       "      <td>0.256580</td>\n",
       "      <td>0.590426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.583633</td>\n",
       "      <td>0.065258</td>\n",
       "      <td>0.193436</td>\n",
       "      <td>0.476849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066496</td>\n",
       "      <td>0.081577</td>\n",
       "      <td>0.490058</td>\n",
       "      <td>0.066016</td>\n",
       "      <td>0.257006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.565107</td>\n",
       "      <td>0.128583</td>\n",
       "      <td>0.226642</td>\n",
       "      <td>0.454056</td>\n",
       "      <td>0.043323</td>\n",
       "      <td>0.289472</td>\n",
       "      <td>0.385452</td>\n",
       "      <td>0.528915</td>\n",
       "      <td>0.085360</td>\n",
       "      <td>0.378504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.560794</td>\n",
       "      <td>0.043767</td>\n",
       "      <td>0.109030</td>\n",
       "      <td>0.397881</td>\n",
       "      <td>0.039116</td>\n",
       "      <td>0.234280</td>\n",
       "      <td>0.331671</td>\n",
       "      <td>0.533718</td>\n",
       "      <td>0.021119</td>\n",
       "      <td>0.291103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.576938</td>\n",
       "      <td>0.023315</td>\n",
       "      <td>0.269479</td>\n",
       "      <td>0.537453</td>\n",
       "      <td>0.057453</td>\n",
       "      <td>0.264545</td>\n",
       "      <td>0.343759</td>\n",
       "      <td>0.558151</td>\n",
       "      <td>0.085127</td>\n",
       "      <td>0.496313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.568985</td>\n",
       "      <td>0.021830</td>\n",
       "      <td>0.240357</td>\n",
       "      <td>0.470001</td>\n",
       "      <td>0.043066</td>\n",
       "      <td>0.260311</td>\n",
       "      <td>0.369469</td>\n",
       "      <td>0.539569</td>\n",
       "      <td>0.063624</td>\n",
       "      <td>0.166171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.570925</td>\n",
       "      <td>0.023129</td>\n",
       "      <td>0.245394</td>\n",
       "      <td>0.478363</td>\n",
       "      <td>0.063858</td>\n",
       "      <td>0.249261</td>\n",
       "      <td>0.387381</td>\n",
       "      <td>0.490882</td>\n",
       "      <td>0.148395</td>\n",
       "      <td>0.438709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.575856</td>\n",
       "      <td>0.088256</td>\n",
       "      <td>0.129507</td>\n",
       "      <td>0.506911</td>\n",
       "      <td>0.064821</td>\n",
       "      <td>0.311813</td>\n",
       "      <td>0.381826</td>\n",
       "      <td>0.596509</td>\n",
       "      <td>0.021478</td>\n",
       "      <td>0.316097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.593087</td>\n",
       "      <td>0.110286</td>\n",
       "      <td>0.172394</td>\n",
       "      <td>0.437488</td>\n",
       "      <td>0.065430</td>\n",
       "      <td>0.308979</td>\n",
       "      <td>0.381879</td>\n",
       "      <td>0.540862</td>\n",
       "      <td>0.043577</td>\n",
       "      <td>0.362397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.589461</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110820</td>\n",
       "      <td>0.437657</td>\n",
       "      <td>0.041024</td>\n",
       "      <td>0.329995</td>\n",
       "      <td>0.389101</td>\n",
       "      <td>0.510433</td>\n",
       "      <td>0.021549</td>\n",
       "      <td>0.232563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.539962</td>\n",
       "      <td>0.021410</td>\n",
       "      <td>0.250489</td>\n",
       "      <td>0.465845</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.207411</td>\n",
       "      <td>0.272182</td>\n",
       "      <td>0.543215</td>\n",
       "      <td>0.043672</td>\n",
       "      <td>0.299537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.566416</td>\n",
       "      <td>0.047316</td>\n",
       "      <td>0.179450</td>\n",
       "      <td>0.473246</td>\n",
       "      <td>0.021435</td>\n",
       "      <td>0.176723</td>\n",
       "      <td>0.365245</td>\n",
       "      <td>0.566965</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.206016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Elec13    Elec13    Elec28    Elec23    Elec13    Elec13    Elec13  \\\n",
       "0   0.577629  0.022112  0.197307  0.450812  0.022031  0.211105  0.330204   \n",
       "1   0.559443  0.044613  0.063940  0.478528  0.000000  0.134694  0.211634   \n",
       "2   0.580369  0.105130  0.168667  0.495886  0.074503  0.222271  0.320779   \n",
       "3   0.565693  0.022738  0.067315  0.222778  0.072687  0.234821  0.333539   \n",
       "4   0.554783  0.022106  0.235868  0.464825  0.037580  0.226030  0.310430   \n",
       "5   0.563122  0.022099  0.089261  0.367501  0.095056  0.278702  0.401454   \n",
       "6   0.563253  0.022067  0.083227  0.459194  0.038552  0.277262  0.317500   \n",
       "7   0.671194  0.024370  0.024192  0.376787  0.000000  0.234779  0.490576   \n",
       "8   0.586149  0.066671  0.257483  0.430835  0.018184  0.180920  0.248558   \n",
       "9   0.579051  0.067546  0.237269  0.555016  0.064144  0.286766  0.375275   \n",
       "10  0.606855  0.000000  0.112776  0.530862  0.043565  0.204148  0.302097   \n",
       "11  0.586252  0.130512  0.186763  0.430320  0.113892  0.280739  0.417009   \n",
       "12  0.570543  0.085980  0.084522  0.364421  0.036189  0.184371  0.358935   \n",
       "13  0.580475  0.000000  0.067292  0.416651  0.064399  0.247290  0.351717   \n",
       "14  0.602469  0.112858  0.195274  0.479619  0.069805  0.335571  0.419032   \n",
       "15  0.570039  0.045900  0.155313  0.406251  0.037632  0.281599  0.336903   \n",
       "16  0.585510  0.045414  0.219907  0.482593  0.000000  0.202178  0.330515   \n",
       "17  0.569974  0.045189  0.257916  0.449084  0.019336  0.251213  0.319750   \n",
       "18  0.564617  0.023085  0.151148  0.458802  0.068153  0.291989  0.377784   \n",
       "19  0.565474  0.045466  0.183215  0.401783  0.022575  0.228363  0.291789   \n",
       "20  0.581649  0.047800  0.115510  0.454538  0.088683  0.270246  0.397292   \n",
       "21  0.570040  0.065904  0.277162  0.440333  0.000000  0.113946  0.206032   \n",
       "22  0.537267  0.022024  0.088337  0.390925  0.025079  0.125919  0.298204   \n",
       "23  0.563113  0.022294  0.236636  0.410678  0.036721  0.248991  0.334765   \n",
       "24  0.557641  0.023499  0.149235  0.498261  0.021020  0.109088  0.211649   \n",
       "25  0.569897  0.043927  0.064524  0.218277  0.060601  0.219519  0.293134   \n",
       "26  0.557178  0.043556  0.126881  0.507864  0.000000  0.092998  0.247769   \n",
       "27  0.557425  0.022322  0.127920  0.334561  0.062176  0.281481  0.378818   \n",
       "28  0.587911  0.023004  0.288044  0.533077  0.000000  0.159328  0.249935   \n",
       "29  0.589917  0.067485  0.257717  0.438865  0.060723  0.238011  0.356814   \n",
       "30  0.571514  0.065564  0.235282  0.523355  0.076210  0.275851  0.343841   \n",
       "31  0.550737  0.043059  0.106154  0.452051  0.019653  0.140408  0.237625   \n",
       "32  0.579386  0.109821  0.148567  0.438290  0.055013  0.254554  0.334215   \n",
       "33  0.568747  0.067465  0.062961  0.379157  0.059822  0.190411  0.243342   \n",
       "34  0.546917  0.021999  0.187181  0.407709  0.041091  0.205274  0.307977   \n",
       "35  0.571025  0.044762  0.232757  0.508099  0.038959  0.186135  0.253841   \n",
       "36  0.562400  0.045367  0.283990  0.429595  0.062674  0.300304  0.405650   \n",
       "37  0.541559  0.044680  0.105221  0.458880  0.061094  0.247730  0.333738   \n",
       "38  0.564037  0.043939  0.241345  0.472884  0.035595  0.240809  0.322133   \n",
       "39  0.583633  0.065258  0.193436  0.476849  0.000000  0.066496  0.081577   \n",
       "40  0.565107  0.128583  0.226642  0.454056  0.043323  0.289472  0.385452   \n",
       "41  0.560794  0.043767  0.109030  0.397881  0.039116  0.234280  0.331671   \n",
       "42  0.576938  0.023315  0.269479  0.537453  0.057453  0.264545  0.343759   \n",
       "43  0.568985  0.021830  0.240357  0.470001  0.043066  0.260311  0.369469   \n",
       "44  0.570925  0.023129  0.245394  0.478363  0.063858  0.249261  0.387381   \n",
       "45  0.575856  0.088256  0.129507  0.506911  0.064821  0.311813  0.381826   \n",
       "46  0.593087  0.110286  0.172394  0.437488  0.065430  0.308979  0.381879   \n",
       "47  0.589461  0.000000  0.110820  0.437657  0.041024  0.329995  0.389101   \n",
       "48  0.539962  0.021410  0.250489  0.465845  0.000000  0.207411  0.272182   \n",
       "49  0.566416  0.047316  0.179450  0.473246  0.021435  0.176723  0.365245   \n",
       "\n",
       "      Elec13    Elec13    Elec13  \n",
       "0   0.481370  0.000000  0.171078  \n",
       "1   0.578711  0.085965  0.275153  \n",
       "2   0.458076  0.044019  0.322039  \n",
       "3   0.511042  0.020971  0.185582  \n",
       "4   0.484789  0.063625  0.271823  \n",
       "5   0.433278  0.087195  0.340410  \n",
       "6   0.591007  0.042655  0.335736  \n",
       "7   0.189263  0.150065  0.450446  \n",
       "8   0.480367  0.000000  0.172383  \n",
       "9   0.493950  0.085978  0.503399  \n",
       "10  0.247180  0.000000  0.085011  \n",
       "11  0.555134  0.106215  0.354219  \n",
       "12  0.564878  0.214780  0.613309  \n",
       "13  0.271891  0.022143  0.215590  \n",
       "14  0.502037  0.000000  0.213493  \n",
       "15  0.549891  0.088064  0.429423  \n",
       "16  0.408337  0.000000  0.128008  \n",
       "17  0.529668  0.196494  0.405479  \n",
       "18  0.483817  0.109767  0.302689  \n",
       "19  0.425812  0.044453  0.432131  \n",
       "20  0.062598  0.022435  0.300389  \n",
       "21  0.512929  0.108348  0.295730  \n",
       "22  0.464825  0.065594  0.256344  \n",
       "23  0.536999  0.043248  0.169479  \n",
       "24  0.460806  0.000000  0.171027  \n",
       "25  0.349785  0.000000  0.126062  \n",
       "26  0.477698  0.279952  0.532413  \n",
       "27  0.552960  0.021646  0.211587  \n",
       "28  0.551554  0.063261  0.396631  \n",
       "29  0.543100  0.043215  0.191025  \n",
       "30  0.540671  0.021431  0.252997  \n",
       "31  0.455313  0.131133  0.384062  \n",
       "32  0.560956  0.021746  0.230690  \n",
       "33  0.525273  0.021380  0.186924  \n",
       "34  0.555146  0.172619  0.424391  \n",
       "35  0.443868  0.000000  0.077734  \n",
       "36  0.464101  0.064177  0.353759  \n",
       "37  0.533726  0.044835  0.426582  \n",
       "38  0.549960  0.256580  0.590426  \n",
       "39  0.490058  0.066016  0.257006  \n",
       "40  0.528915  0.085360  0.378504  \n",
       "41  0.533718  0.021119  0.291103  \n",
       "42  0.558151  0.085127  0.496313  \n",
       "43  0.539569  0.063624  0.166171  \n",
       "44  0.490882  0.148395  0.438709  \n",
       "45  0.596509  0.021478  0.316097  \n",
       "46  0.540862  0.043577  0.362397  \n",
       "47  0.510433  0.021549  0.232563  \n",
       "48  0.543215  0.043672  0.299537  \n",
       "49  0.566965  0.000000  0.206016  "
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "#2eme selection des 21 variables\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_AD_MCI_selection1, [0]*28+[1]*22, test_size=0.33, random_state=0)\n",
    "model = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Selection des variables donc l'importance est superieure à la valeur moyenne des importances\n",
    "selection2 = SelectFromModel(model,threshold=mean_importance,prefit=True)\n",
    "selected_feat2 = data_AD_MCI_selection1.columns[(selection2.get_support())]\n",
    "print(selected_feat2)\n",
    "\n",
    "#Creation de la derniere base de données avec que les variables selectionnees\n",
    "data_AD_MCI_selection2 = selection2.transform(data_AD_MCI_selection1)\n",
    "data_AD_MCI_selection2 = dataframe_creator(data_AD_MCI_selection2,selected_feat2)\n",
    "#data_AD_MCI_selection2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y a un probleme avec les noms des variables, c'est pas pratique, faudra les renomer en fct de la frequence te du seuil. ici par exemple on sait pas à quelle partir de quel seuil et de quelle frequence a ete selectionne chaque electrode. Je vais les modifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCI_MCI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "#liste des variables de la premiere phase de selection\n",
    "selected_var = []\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_SCI_MCI_ALPHA_100, [0]*22+[1]*22, test_size=0.33, random_state=0)\n",
    "model1 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model1.fit(X_train, y_train)\n",
    "var1 = np.argmax(model2.feature_importances_)+1\n",
    "selected_var.append(var1)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_SCI_MCI_ALPHA_10, [0]*22+[1]*22, test_size=0.33, random_state=0)\n",
    "model2 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model2.fit(X_train, y_train)\n",
    "var2 = np.argmax(model2.feature_importances_)+1\n",
    "selected_var.append(var2)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_SCI_MCI_ALPHA_20, [0]*22+[1]*22, test_size=0.33, random_state=0)\n",
    "model3 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model3.fit(X_train, y_train)\n",
    "var3 = np.argmax(model3.feature_importances_)+1\n",
    "selected_var.append(var3)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_SCI_MCI_ALPHA_30, [0]*22+[1]*22, test_size=0.33, random_state=0)\n",
    "model4 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model4.fit(X_train, y_train)\n",
    "var4 = np.argmax(model4.feature_importances_)+1\n",
    "selected_var.append(var4)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_SCI_MCI_ALPHA_50, [0]*22+[1]*22, test_size=0.33, random_state=0)\n",
    "model5 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model5.fit(X_train, y_train)\n",
    "var5 = np.argmax(model5.feature_importances_)\n",
    "selected_var.append(var5)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_SCI_MCI_ALPHA_70, [0]*22+[1]*22, test_size=0.33, random_state=0)\n",
    "model6 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model6.fit(X_train, y_train)\n",
    "var6 = np.argmax(model6.feature_importances_)+1\n",
    "selected_var.append(var6)\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_SCI_MCI_BETA_100, [0]*22+[1]*22, test_size=0.33, random_state=0)\n",
    "model7 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model7.fit(X_train, y_train)\n",
    "var7 = np.argmax(model7.feature_importances_)+1\n",
    "selected_var.append(var7)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_SCI_MCI_BETA_10, [0]*22+[1]*22, test_size=0.33, random_state=0)\n",
    "model8 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model8.fit(X_train, y_train)\n",
    "var8 = np.argmax(model8.feature_importances_)+1\n",
    "selected_var.append(var8)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_SCI_MCI_BETA_20, [0]*22+[1]*22, test_size=0.33, random_state=0)\n",
    "model9 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model9.fit(X_train, y_train)\n",
    "var9 = np.argmax(model9.feature_importances_)+1\n",
    "selected_var.append(var9)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_SCI_MCI_BETA_30, [0]*22+[1]*22, test_size=0.33, random_state=0)\n",
    "model10 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model10.fit(X_train, y_train)\n",
    "var10 = np.argmax(model10.feature_importances_)+1\n",
    "selected_var.append(var10)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_SCI_MCI_BETA_50, [0]*22+[1]*22, test_size=0.33, random_state=0)\n",
    "model11 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model11.fit(X_train, y_train)\n",
    "var11 = np.argmax(model11.feature_importances_)+1\n",
    "selected_var.append(var11)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_SCI_MCI_BETA_70, [0]*22+[1]*22, test_size=0.33, random_state=0)\n",
    "model12 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model12.fit(X_train, y_train)\n",
    "var12 = np.argmax(model12.feature_importances_)+1\n",
    "selected_var.append(var12)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_SCI_MCI_DELTA_100, [0]*22+[1]*22, test_size=0.33, random_state=0)\n",
    "model13 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model13.fit(X_train, y_train)\n",
    "var13 = np.argmax(model13.feature_importances_)+1\n",
    "selected_var.append(var13)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_SCI_MCI_DELTA_10, [0]*22+[1]*22, test_size=0.33, random_state=0)\n",
    "model14 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model14.fit(X_train, y_train)\n",
    "var14 = np.argmax(model14.feature_importances_)+1\n",
    "selected_var.append(var14)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_SCI_MCI_DELTA_20, [0]*22+[1]*22, test_size=0.33, random_state=0)\n",
    "model15 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model15.fit(X_train, y_train)\n",
    "var15 = np.argmax(model15.feature_importances_)+1\n",
    "selected_var.append(var15)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_SCI_MCI_DELTA_30, [0]*22+[1]*22, test_size=0.33, random_state=0)\n",
    "model16 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model16.fit(X_train, y_train)\n",
    "var16 = np.argmax(model16.feature_importances_)+1\n",
    "selected_var.append(var16)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_SCI_MCI_DELTA_50, [0]*22+[1]*22, test_size=0.33, random_state=0)\n",
    "model17 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model17.fit(X_train, y_train)\n",
    "var17 = np.argmax(model17.feature_importances_)+1\n",
    "selected_var.append(var17)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_SCI_MCI_DELTA_70, [0]*22+[1]*22, test_size=0.33, random_state=0)\n",
    "model18 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model18.fit(X_train, y_train)\n",
    "var18 = np.argmax(model18.feature_importances_)+1\n",
    "selected_var.append(var18)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_SCI_MCI_THETA_100, [0]*22+[1]*22, test_size=0.33, random_state=0)\n",
    "model19 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model19.fit(X_train, y_train)\n",
    "var19 = np.argmax(model19.feature_importances_)+1\n",
    "selected_var.append(var19)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_SCI_MCI_THETA_10, [0]*22+[1]*22, test_size=0.33, random_state=0)\n",
    "model20 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model20.fit(X_train, y_train)\n",
    "var20 = np.argmax(model20.feature_importances_)+1\n",
    "selected_var.append(var20)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_SCI_MCI_THETA_20, [0]*22+[1]*22, test_size=0.33, random_state=0)\n",
    "model21 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model21.fit(X_train, y_train)\n",
    "var21 = np.argmax(model21.feature_importances_)+1\n",
    "selected_var.append(var21)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_SCI_MCI_THETA_30, [0]*22+[1]*22, test_size=0.33, random_state=0)\n",
    "model22 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model22.fit(X_train, y_train)\n",
    "var22 = np.argmax(model22.feature_importances_)+1\n",
    "selected_var.append(var22)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_SCI_MCI_THETA_50, [0]*22+[1]*22, test_size=0.33, random_state=0)\n",
    "model23 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model23.fit(X_train, y_train)\n",
    "var23 = np.argmax(model23.feature_importances_)+1\n",
    "selected_var.append(var23)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_SCI_MCI_THETA_70, [0]*22+[1]*22, test_size=0.33, random_state=0)\n",
    "model24 = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model24.fit(X_train, y_train)\n",
    "var24 = np.argmax(model24.feature_importances_)+1\n",
    "selected_var.append(var24)\n",
    "\n",
    "#print(selected_var)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation d'une dataframe correspondante avec la variable selectionnee pour chaque cas de (freq,seuil)\n",
    "\n",
    "data_SCI_MCI_ALPHA_100_new = dataframe_creator(data_SCI_MCI_ALPHA_100['E.alpha_100'+str(var1)],['E.Alpha100'+str(var1)])\n",
    "data_SCI_MCI_ALPHA_10_new = dataframe_creator(data_SCI_MCI_ALPHA_10['E.alpha_10'+str(var2)],['E.alpha10'+str(var2)])\n",
    "data_SCI_MCI_ALPHA_20_new = dataframe_creator(data_SCI_MCI_ALPHA_20['E.alpha_20'+str(var3)],['E.alpha20'+str(var3)])\n",
    "data_SCI_MCI_ALPHA_30_new = dataframe_creator(data_SCI_MCI_ALPHA_30['E.alpha_30'+str(var4)],['E.alpha30'+str(var4)])\n",
    "data_SCI_MCI_ALPHA_50_new = dataframe_creator(data_SCI_MCI_ALPHA_50['E.alpha_50'+str(var5)],['E.alpha50'+str(var5)])\n",
    "data_SCI_MCI_ALPHA_70_new = dataframe_creator(data_SCI_MCI_ALPHA_70['E.alpha_70'+str(var6)],['E.alpha70'+str(var6)])\n",
    "\n",
    "\n",
    "data_SCI_MCI_BETA_100_new = dataframe_creator(data_SCI_MCI_BETA_100['Elec'+str(var7)],['Elec'+str(var7)])\n",
    "data_SCI_MCI_BETA_10_new = dataframe_creator(data_SCI_MCI_BETA_10['Elec'+str(var8)],['Elec'+str(var8)])\n",
    "data_SCI_MCI_BETA_20_new = dataframe_creator(data_SCI_MCI_BETA_20['Elec'+str(var9)],['Elec'+str(var9)])\n",
    "data_SCI_MCI_BETA_30_new = dataframe_creator(data_SCI_MCI_BETA_30['Elec'+str(var10)],['Elec'+str(var10)])\n",
    "data_SCI_MCI_BETA_50_new = dataframe_creator(data_SCI_MCI_BETA_50['Elec'+str(var11)],['Elec'+str(var11)])\n",
    "data_SCI_MCI_BETA_70_new = dataframe_creator(data_SCI_MCI_BETA_70['Elec'+str(var12)],['Elec'+str(var12)])\n",
    "\n",
    "data_SCI_MCI_DELTA_100_new = dataframe_creator(data_SCI_MCI_DELTA_100['Elec'+str(var13)],['Elec'+str(var13)])\n",
    "data_SCI_MCI_DELTA_10_new = dataframe_creator(data_SCI_MCI_DELTA_10['Elec'+str(var14)],['Elec'+str(var14)])\n",
    "data_SCI_MCI_DELTA_20_new = dataframe_creator(data_SCI_MCI_DELTA_20['Elec'+str(var15)],['Elec'+str(var15)])\n",
    "data_SCI_MCI_DELTA_30_new = dataframe_creator(data_SCI_MCI_DELTA_30['Elec'+str(var16)],['Elec'+str(var16)])\n",
    "data_SCI_MCI_DELTA_50_new = dataframe_creator(data_SCI_MCI_DELTA_50['Elec'+str(var17)],['Elec'+str(var17)])\n",
    "data_SCI_MCI_DELTA_70_new = dataframe_creator(data_SCI_MCI_DELTA_70['Elec'+str(var18)],['Elec'+str(var18)])\n",
    "\n",
    "data_SCI_MCI_THETA_100_new = dataframe_creator(data_SCI_MCI_THETA_100['Elec'+str(var19)],['Elec'+str(var19)])\n",
    "data_SCI_MCI_THETA_10_new = dataframe_creator(data_SCI_MCI_THETA_10['Elec'+str(var20)],['Elec'+str(var20)])\n",
    "data_SCI_MCI_THETA_20_new = dataframe_creator(data_SCI_MCI_THETA_20['Elec'+str(var21)],['Elec'+str(var21)])\n",
    "data_SCI_MCI_THETA_30_new = dataframe_creator(data_SCI_MCI_THETA_30['Elec'+str(var22)],['Elec'+str(var22)])\n",
    "data_SCI_MCI_THETA_50_new = dataframe_creator(data_SCI_MCI_THETA_50['Elec'+str(var23)],['Elec'+str(var23)])\n",
    "data_SCI_MCI_THETA_70_new = dataframe_creator(data_SCI_MCI_THETA_70['Elec'+str(var24)],['Elec'+str(var24)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation d'une base de données avec les 24  variables selectionnees dans la premiere etape de selection\n",
    "datas_SCI_MCI = [data_SCI_MCI_ALPHA_100_new,data_SCI_MCI_ALPHA_10_new,data_SCI_MCI_ALPHA_20_new,data_SCI_MCI_ALPHA_30_new,data_SCI_MCI_ALPHA_50_new,data_SCI_MCI_ALPHA_70_new,data_SCI_MCI_BETA_100_new,data_SCI_MCI_BETA_10_new,data_SCI_MCI_BETA_20_new,data_SCI_MCI_BETA_30_new,data_SCI_MCI_BETA_50_new,data_SCI_MCI_BETA_70_new,data_SCI_MCI_DELTA_100_new,data_SCI_MCI_DELTA_10_new,data_SCI_MCI_DELTA_20_new,data_SCI_MCI_DELTA_30_new,data_SCI_MCI_DELTA_50_new,data_SCI_MCI_DELTA_70_new,data_SCI_MCI_THETA_100_new,data_SCI_MCI_THETA_10_new,data_SCI_MCI_THETA_20_new,data_SCI_MCI_THETA_30_new,data_SCI_MCI_THETA_50_new,data_SCI_MCI_THETA_70_new]\n",
    "data_SCI_MCI_selection1 = pd.concat((iDF for iDF in datas_SCI_MCI),axis=1, join='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elec18</th>\n",
       "      <th>Elec11</th>\n",
       "      <th>Elec11</th>\n",
       "      <th>Elec27</th>\n",
       "      <th>Elec2</th>\n",
       "      <th>Elec2</th>\n",
       "      <th>Elec2</th>\n",
       "      <th>Elec9</th>\n",
       "      <th>Elec9</th>\n",
       "      <th>Elec7</th>\n",
       "      <th>Elec7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.047095</td>\n",
       "      <td>0.203634</td>\n",
       "      <td>0.605132</td>\n",
       "      <td>0.045351</td>\n",
       "      <td>0.555824</td>\n",
       "      <td>0.613990</td>\n",
       "      <td>0.613990</td>\n",
       "      <td>0.009339</td>\n",
       "      <td>0.009339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.090414</td>\n",
       "      <td>0.200384</td>\n",
       "      <td>0.464801</td>\n",
       "      <td>0.061228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099496</td>\n",
       "      <td>0.214931</td>\n",
       "      <td>0.319596</td>\n",
       "      <td>0.151462</td>\n",
       "      <td>0.215283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.043862</td>\n",
       "      <td>0.176347</td>\n",
       "      <td>0.458460</td>\n",
       "      <td>0.102765</td>\n",
       "      <td>0.229948</td>\n",
       "      <td>0.264253</td>\n",
       "      <td>0.423035</td>\n",
       "      <td>0.083698</td>\n",
       "      <td>0.226812</td>\n",
       "      <td>0.043295</td>\n",
       "      <td>0.086236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.072050</td>\n",
       "      <td>0.306140</td>\n",
       "      <td>0.622621</td>\n",
       "      <td>0.026133</td>\n",
       "      <td>0.391896</td>\n",
       "      <td>0.493673</td>\n",
       "      <td>0.637646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.091589</td>\n",
       "      <td>0.132619</td>\n",
       "      <td>0.376898</td>\n",
       "      <td>0.022698</td>\n",
       "      <td>0.573799</td>\n",
       "      <td>0.573799</td>\n",
       "      <td>0.573799</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.203733</td>\n",
       "      <td>0.270295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.047098</td>\n",
       "      <td>0.185347</td>\n",
       "      <td>0.528986</td>\n",
       "      <td>0.023218</td>\n",
       "      <td>0.602206</td>\n",
       "      <td>0.622008</td>\n",
       "      <td>0.622008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.293529</td>\n",
       "      <td>0.404478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.067775</td>\n",
       "      <td>0.200538</td>\n",
       "      <td>0.603085</td>\n",
       "      <td>0.063780</td>\n",
       "      <td>0.398909</td>\n",
       "      <td>0.543032</td>\n",
       "      <td>0.543032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065664</td>\n",
       "      <td>0.108779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.043899</td>\n",
       "      <td>0.086930</td>\n",
       "      <td>0.429832</td>\n",
       "      <td>0.081212</td>\n",
       "      <td>0.156762</td>\n",
       "      <td>0.245543</td>\n",
       "      <td>0.408962</td>\n",
       "      <td>0.124379</td>\n",
       "      <td>0.185570</td>\n",
       "      <td>0.064616</td>\n",
       "      <td>0.149792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.113673</td>\n",
       "      <td>0.131175</td>\n",
       "      <td>0.468151</td>\n",
       "      <td>0.080428</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.108863</td>\n",
       "      <td>0.020208</td>\n",
       "      <td>0.079296</td>\n",
       "      <td>0.107773</td>\n",
       "      <td>0.171375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.043637</td>\n",
       "      <td>0.257855</td>\n",
       "      <td>0.471519</td>\n",
       "      <td>0.094759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.122753</td>\n",
       "      <td>0.182707</td>\n",
       "      <td>0.107892</td>\n",
       "      <td>0.193018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.065624</td>\n",
       "      <td>0.212674</td>\n",
       "      <td>0.509185</td>\n",
       "      <td>0.057990</td>\n",
       "      <td>0.017304</td>\n",
       "      <td>0.017304</td>\n",
       "      <td>0.166878</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016502</td>\n",
       "      <td>0.197575</td>\n",
       "      <td>0.327354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.111483</td>\n",
       "      <td>0.105001</td>\n",
       "      <td>0.496515</td>\n",
       "      <td>0.037674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.124997</td>\n",
       "      <td>0.083083</td>\n",
       "      <td>0.123671</td>\n",
       "      <td>0.043347</td>\n",
       "      <td>0.064544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.178973</td>\n",
       "      <td>0.044169</td>\n",
       "      <td>0.449190</td>\n",
       "      <td>0.078965</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.029924</td>\n",
       "      <td>0.196656</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110978</td>\n",
       "      <td>0.176752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.065010</td>\n",
       "      <td>0.108063</td>\n",
       "      <td>0.345786</td>\n",
       "      <td>0.060264</td>\n",
       "      <td>0.016973</td>\n",
       "      <td>0.016973</td>\n",
       "      <td>0.224910</td>\n",
       "      <td>0.039336</td>\n",
       "      <td>0.077619</td>\n",
       "      <td>0.152871</td>\n",
       "      <td>0.303011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.067449</td>\n",
       "      <td>0.233716</td>\n",
       "      <td>0.554610</td>\n",
       "      <td>0.098005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.107252</td>\n",
       "      <td>0.021419</td>\n",
       "      <td>0.042008</td>\n",
       "      <td>0.108930</td>\n",
       "      <td>0.259926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.068067</td>\n",
       "      <td>0.150036</td>\n",
       "      <td>0.426998</td>\n",
       "      <td>0.097307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013271</td>\n",
       "      <td>0.019375</td>\n",
       "      <td>0.038501</td>\n",
       "      <td>0.109775</td>\n",
       "      <td>0.109775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.046814</td>\n",
       "      <td>0.222269</td>\n",
       "      <td>0.487702</td>\n",
       "      <td>0.040132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057178</td>\n",
       "      <td>0.017107</td>\n",
       "      <td>0.050627</td>\n",
       "      <td>0.108058</td>\n",
       "      <td>0.150556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.043455</td>\n",
       "      <td>0.259869</td>\n",
       "      <td>0.567220</td>\n",
       "      <td>0.040783</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047746</td>\n",
       "      <td>0.047931</td>\n",
       "      <td>0.125959</td>\n",
       "      <td>0.021895</td>\n",
       "      <td>0.043489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.047825</td>\n",
       "      <td>0.047705</td>\n",
       "      <td>0.335026</td>\n",
       "      <td>0.045512</td>\n",
       "      <td>0.693251</td>\n",
       "      <td>0.693251</td>\n",
       "      <td>0.693251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.180357</td>\n",
       "      <td>0.202055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.046526</td>\n",
       "      <td>0.136198</td>\n",
       "      <td>0.423054</td>\n",
       "      <td>0.079470</td>\n",
       "      <td>0.520488</td>\n",
       "      <td>0.520488</td>\n",
       "      <td>0.520488</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044241</td>\n",
       "      <td>0.065710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141830</td>\n",
       "      <td>0.498770</td>\n",
       "      <td>0.045190</td>\n",
       "      <td>0.297083</td>\n",
       "      <td>0.487320</td>\n",
       "      <td>0.632108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006233</td>\n",
       "      <td>0.175685</td>\n",
       "      <td>0.305156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.044105</td>\n",
       "      <td>0.206344</td>\n",
       "      <td>0.514899</td>\n",
       "      <td>0.058841</td>\n",
       "      <td>0.050960</td>\n",
       "      <td>0.065959</td>\n",
       "      <td>0.312997</td>\n",
       "      <td>0.036902</td>\n",
       "      <td>0.091203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.090411</td>\n",
       "      <td>0.066780</td>\n",
       "      <td>0.416109</td>\n",
       "      <td>0.040484</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.167990</td>\n",
       "      <td>0.043572</td>\n",
       "      <td>0.106535</td>\n",
       "      <td>0.042683</td>\n",
       "      <td>0.084540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.133064</td>\n",
       "      <td>0.021761</td>\n",
       "      <td>0.264086</td>\n",
       "      <td>0.101757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.107070</td>\n",
       "      <td>0.164664</td>\n",
       "      <td>0.244733</td>\n",
       "      <td>0.021459</td>\n",
       "      <td>0.106429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.108834</td>\n",
       "      <td>0.043260</td>\n",
       "      <td>0.368161</td>\n",
       "      <td>0.096148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085387</td>\n",
       "      <td>0.224164</td>\n",
       "      <td>0.323820</td>\n",
       "      <td>0.043480</td>\n",
       "      <td>0.064710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.065782</td>\n",
       "      <td>0.125169</td>\n",
       "      <td>0.355565</td>\n",
       "      <td>0.080580</td>\n",
       "      <td>0.033789</td>\n",
       "      <td>0.049134</td>\n",
       "      <td>0.231798</td>\n",
       "      <td>0.090037</td>\n",
       "      <td>0.159792</td>\n",
       "      <td>0.065163</td>\n",
       "      <td>0.214922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.130628</td>\n",
       "      <td>0.105099</td>\n",
       "      <td>0.466831</td>\n",
       "      <td>0.130327</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014707</td>\n",
       "      <td>0.054601</td>\n",
       "      <td>0.042116</td>\n",
       "      <td>0.103592</td>\n",
       "      <td>0.021391</td>\n",
       "      <td>0.063749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.128829</td>\n",
       "      <td>0.104884</td>\n",
       "      <td>0.381119</td>\n",
       "      <td>0.053125</td>\n",
       "      <td>0.022622</td>\n",
       "      <td>0.022622</td>\n",
       "      <td>0.169223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.135411</td>\n",
       "      <td>0.021134</td>\n",
       "      <td>0.042114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.064040</td>\n",
       "      <td>0.103085</td>\n",
       "      <td>0.348349</td>\n",
       "      <td>0.082282</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133659</td>\n",
       "      <td>0.144739</td>\n",
       "      <td>0.225354</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.109635</td>\n",
       "      <td>0.149370</td>\n",
       "      <td>0.348040</td>\n",
       "      <td>0.083032</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149725</td>\n",
       "      <td>0.017429</td>\n",
       "      <td>0.051294</td>\n",
       "      <td>0.101341</td>\n",
       "      <td>0.181307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.022852</td>\n",
       "      <td>0.345489</td>\n",
       "      <td>0.114140</td>\n",
       "      <td>0.020183</td>\n",
       "      <td>0.063565</td>\n",
       "      <td>0.196738</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021351</td>\n",
       "      <td>0.063216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.066823</td>\n",
       "      <td>0.107860</td>\n",
       "      <td>0.495170</td>\n",
       "      <td>0.116754</td>\n",
       "      <td>0.035003</td>\n",
       "      <td>0.210094</td>\n",
       "      <td>0.455597</td>\n",
       "      <td>0.042969</td>\n",
       "      <td>0.147552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.111633</td>\n",
       "      <td>0.064350</td>\n",
       "      <td>0.462740</td>\n",
       "      <td>0.133056</td>\n",
       "      <td>0.021536</td>\n",
       "      <td>0.036646</td>\n",
       "      <td>0.187882</td>\n",
       "      <td>0.224485</td>\n",
       "      <td>0.283392</td>\n",
       "      <td>0.042599</td>\n",
       "      <td>0.105540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.131321</td>\n",
       "      <td>0.086330</td>\n",
       "      <td>0.427269</td>\n",
       "      <td>0.086580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.265683</td>\n",
       "      <td>0.350936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.145451</td>\n",
       "      <td>0.168650</td>\n",
       "      <td>0.383306</td>\n",
       "      <td>0.067054</td>\n",
       "      <td>0.134517</td>\n",
       "      <td>0.213568</td>\n",
       "      <td>0.328864</td>\n",
       "      <td>0.201594</td>\n",
       "      <td>0.317455</td>\n",
       "      <td>0.021285</td>\n",
       "      <td>0.021285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.045467</td>\n",
       "      <td>0.106500</td>\n",
       "      <td>0.300182</td>\n",
       "      <td>0.102353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.177634</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019180</td>\n",
       "      <td>0.021523</td>\n",
       "      <td>0.063464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.046928</td>\n",
       "      <td>0.043092</td>\n",
       "      <td>0.434878</td>\n",
       "      <td>0.098849</td>\n",
       "      <td>0.017214</td>\n",
       "      <td>0.017214</td>\n",
       "      <td>0.110595</td>\n",
       "      <td>0.062428</td>\n",
       "      <td>0.143145</td>\n",
       "      <td>0.021453</td>\n",
       "      <td>0.063021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.044365</td>\n",
       "      <td>0.044096</td>\n",
       "      <td>0.586544</td>\n",
       "      <td>0.125736</td>\n",
       "      <td>0.022881</td>\n",
       "      <td>0.022881</td>\n",
       "      <td>0.148870</td>\n",
       "      <td>0.020611</td>\n",
       "      <td>0.020611</td>\n",
       "      <td>0.021095</td>\n",
       "      <td>0.041788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.046267</td>\n",
       "      <td>0.088107</td>\n",
       "      <td>0.501889</td>\n",
       "      <td>0.060331</td>\n",
       "      <td>0.037024</td>\n",
       "      <td>0.071150</td>\n",
       "      <td>0.447269</td>\n",
       "      <td>0.127093</td>\n",
       "      <td>0.269272</td>\n",
       "      <td>0.191918</td>\n",
       "      <td>0.296581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.110970</td>\n",
       "      <td>0.066308</td>\n",
       "      <td>0.439111</td>\n",
       "      <td>0.122913</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083931</td>\n",
       "      <td>0.108207</td>\n",
       "      <td>0.192586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.110142</td>\n",
       "      <td>0.086959</td>\n",
       "      <td>0.323651</td>\n",
       "      <td>0.084968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.162154</td>\n",
       "      <td>0.081302</td>\n",
       "      <td>0.120845</td>\n",
       "      <td>0.086878</td>\n",
       "      <td>0.151305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.022875</td>\n",
       "      <td>0.239661</td>\n",
       "      <td>0.594682</td>\n",
       "      <td>0.078003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044787</td>\n",
       "      <td>0.058100</td>\n",
       "      <td>0.114719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.064860</td>\n",
       "      <td>0.083243</td>\n",
       "      <td>0.472952</td>\n",
       "      <td>0.117019</td>\n",
       "      <td>0.016445</td>\n",
       "      <td>0.016445</td>\n",
       "      <td>0.241345</td>\n",
       "      <td>0.257711</td>\n",
       "      <td>0.361029</td>\n",
       "      <td>0.043502</td>\n",
       "      <td>0.065134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.046224</td>\n",
       "      <td>0.043254</td>\n",
       "      <td>0.338348</td>\n",
       "      <td>0.061299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105048</td>\n",
       "      <td>0.105048</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Elec18    Elec11    Elec11    Elec27     Elec2     Elec2     Elec2  \\\n",
       "0   0.047095  0.203634  0.605132  0.045351  0.555824  0.613990  0.613990   \n",
       "1   0.090414  0.200384  0.464801  0.061228  0.000000  0.000000  0.099496   \n",
       "2   0.043862  0.176347  0.458460  0.102765  0.229948  0.264253  0.423035   \n",
       "3   0.072050  0.306140  0.622621  0.026133  0.391896  0.493673  0.637646   \n",
       "4   0.091589  0.132619  0.376898  0.022698  0.573799  0.573799  0.573799   \n",
       "5   0.047098  0.185347  0.528986  0.023218  0.602206  0.622008  0.622008   \n",
       "6   0.067775  0.200538  0.603085  0.063780  0.398909  0.543032  0.543032   \n",
       "7   0.043899  0.086930  0.429832  0.081212  0.156762  0.245543  0.408962   \n",
       "8   0.113673  0.131175  0.468151  0.080428  0.000000  0.000000  0.108863   \n",
       "9   0.043637  0.257855  0.471519  0.094759  0.000000  0.000000  0.000000   \n",
       "10  0.065624  0.212674  0.509185  0.057990  0.017304  0.017304  0.166878   \n",
       "11  0.111483  0.105001  0.496515  0.037674  0.000000  0.000000  0.124997   \n",
       "12  0.178973  0.044169  0.449190  0.078965  0.000000  0.029924  0.196656   \n",
       "13  0.065010  0.108063  0.345786  0.060264  0.016973  0.016973  0.224910   \n",
       "14  0.067449  0.233716  0.554610  0.098005  0.000000  0.000000  0.107252   \n",
       "15  0.068067  0.150036  0.426998  0.097307  0.000000  0.000000  0.013271   \n",
       "16  0.046814  0.222269  0.487702  0.040132  0.000000  0.000000  0.057178   \n",
       "17  0.043455  0.259869  0.567220  0.040783  0.000000  0.000000  0.047746   \n",
       "18  0.047825  0.047705  0.335026  0.045512  0.693251  0.693251  0.693251   \n",
       "19  0.046526  0.136198  0.423054  0.079470  0.520488  0.520488  0.520488   \n",
       "20  0.000000  0.141830  0.498770  0.045190  0.297083  0.487320  0.632108   \n",
       "21  0.044105  0.206344  0.514899  0.058841  0.050960  0.065959  0.312997   \n",
       "22  0.090411  0.066780  0.416109  0.040484  0.000000  0.000000  0.167990   \n",
       "23  0.133064  0.021761  0.264086  0.101757  0.000000  0.016200  0.107070   \n",
       "24  0.108834  0.043260  0.368161  0.096148  0.000000  0.000000  0.085387   \n",
       "25  0.065782  0.125169  0.355565  0.080580  0.033789  0.049134  0.231798   \n",
       "26  0.130628  0.105099  0.466831  0.130327  0.000000  0.014707  0.054601   \n",
       "27  0.128829  0.104884  0.381119  0.053125  0.022622  0.022622  0.169223   \n",
       "28  0.064040  0.103085  0.348349  0.082282  0.000000  0.000000  0.133659   \n",
       "29  0.109635  0.149370  0.348040  0.083032  0.000000  0.000000  0.149725   \n",
       "30  0.068543  0.022852  0.345489  0.114140  0.020183  0.063565  0.196738   \n",
       "31  0.066823  0.107860  0.495170  0.116754  0.035003  0.210094  0.455597   \n",
       "32  0.111633  0.064350  0.462740  0.133056  0.021536  0.036646  0.187882   \n",
       "33  0.131321  0.086330  0.427269  0.086580  0.000000  0.000000  0.000000   \n",
       "34  0.145451  0.168650  0.383306  0.067054  0.134517  0.213568  0.328864   \n",
       "35  0.045467  0.106500  0.300182  0.102353  0.000000  0.000000  0.177634   \n",
       "36  0.046928  0.043092  0.434878  0.098849  0.017214  0.017214  0.110595   \n",
       "37  0.044365  0.044096  0.586544  0.125736  0.022881  0.022881  0.148870   \n",
       "38  0.046267  0.088107  0.501889  0.060331  0.037024  0.071150  0.447269   \n",
       "39  0.110970  0.066308  0.439111  0.122913  0.000000  0.000000  0.083931   \n",
       "40  0.110142  0.086959  0.323651  0.084968  0.000000  0.000000  0.162154   \n",
       "41  0.022875  0.239661  0.594682  0.078003  0.000000  0.000000  0.044787   \n",
       "42  0.064860  0.083243  0.472952  0.117019  0.016445  0.016445  0.241345   \n",
       "43  0.046224  0.043254  0.338348  0.061299  0.000000  0.000000  0.000000   \n",
       "\n",
       "       Elec9     Elec9     Elec7     Elec7  \n",
       "0   0.009339  0.009339  0.000000  0.065221  \n",
       "1   0.214931  0.319596  0.151462  0.215283  \n",
       "2   0.083698  0.226812  0.043295  0.086236  \n",
       "3   0.000000  0.000000  0.000000  0.042893  \n",
       "4   0.000000  0.000000  0.203733  0.270295  \n",
       "5   0.000000  0.000000  0.293529  0.404478  \n",
       "6   0.000000  0.000000  0.065664  0.108779  \n",
       "7   0.124379  0.185570  0.064616  0.149792  \n",
       "8   0.020208  0.079296  0.107773  0.171375  \n",
       "9   0.122753  0.182707  0.107892  0.193018  \n",
       "10  0.000000  0.016502  0.197575  0.327354  \n",
       "11  0.083083  0.123671  0.043347  0.064544  \n",
       "12  0.000000  0.000000  0.110978  0.176752  \n",
       "13  0.039336  0.077619  0.152871  0.303011  \n",
       "14  0.021419  0.042008  0.108930  0.259926  \n",
       "15  0.019375  0.038501  0.109775  0.109775  \n",
       "16  0.017107  0.050627  0.108058  0.150556  \n",
       "17  0.047931  0.125959  0.021895  0.043489  \n",
       "18  0.000000  0.000000  0.180357  0.202055  \n",
       "19  0.000000  0.000000  0.044241  0.065710  \n",
       "20  0.000000  0.006233  0.175685  0.305156  \n",
       "21  0.036902  0.091203  0.000000  0.064239  \n",
       "22  0.043572  0.106535  0.042683  0.084540  \n",
       "23  0.164664  0.244733  0.021459  0.106429  \n",
       "24  0.224164  0.323820  0.043480  0.064710  \n",
       "25  0.090037  0.159792  0.065163  0.214922  \n",
       "26  0.042116  0.103592  0.021391  0.063749  \n",
       "27  0.000000  0.135411  0.021134  0.042114  \n",
       "28  0.144739  0.225354  0.000000  0.042323  \n",
       "29  0.017429  0.051294  0.101341  0.181307  \n",
       "30  0.000000  0.000000  0.021351  0.063216  \n",
       "31  0.042969  0.147552  0.000000  0.021436  \n",
       "32  0.224485  0.283392  0.042599  0.105540  \n",
       "33  0.265683  0.350936  0.000000  0.000000  \n",
       "34  0.201594  0.317455  0.021285  0.021285  \n",
       "35  0.000000  0.019180  0.021523  0.063464  \n",
       "36  0.062428  0.143145  0.021453  0.063021  \n",
       "37  0.020611  0.020611  0.021095  0.041788  \n",
       "38  0.127093  0.269272  0.191918  0.296581  \n",
       "39  0.108207  0.192586  0.000000  0.000000  \n",
       "40  0.081302  0.120845  0.086878  0.151305  \n",
       "41  0.058100  0.114719  0.000000  0.042563  \n",
       "42  0.257711  0.361029  0.043502  0.065134  \n",
       "43  0.105048  0.105048  0.000000  0.041720  "
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "#2eme selection des 21 variables\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_SCI_MCI_selection1, [0]*22+[1]*22, test_size=0.33, random_state=0)\n",
    "model = ExtraTreesClassifier(n_estimators=100, random_state=0,max_depth=2 )\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "importance = list(model.feature_importances_)\n",
    "mean_importance = sum()\n",
    "\n",
    "#Selection des variables donc l'importance est superieure à la valeur moyenne des importances (J' ai pris ca comme seuil mais je sais ce que vous en penser)\n",
    "selection2 = SelectFromModel(model,threshold=mean_importance,prefit=True)\n",
    "selected_feat2 = data_SCI_MCI_selection1.columns[(selection2.get_support())]\n",
    "\n",
    "#Creation de la derniere base de données avec que les variables selectionnees\n",
    "data_SCI_MCI_selection2 = selection2.transform(data_SCI_MCI_selection1)\n",
    "data_SCI_MCI_selection2 = dataframe_creator(data_SCI_MCI_selection2,selected_feat2)\n",
    "\n",
    "data_SCI_MCI_selection2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C'est juste des essais de quelques modeles, ca va etre changé\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuaracy 0.56\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "y = [0]*28+[1]*22\n",
    "X = data_AD_MCI_selection1\n",
    "score = []\n",
    "\n",
    "num_folds = 10\n",
    "loocv = LeaveOneOut()\n",
    "model = svm.SVC()\n",
    "results = cross_val_score(model, X, y, cv=loocv)\n",
    "print('accuaracy',results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score accuaracy for SVM = 0.5882352941176471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm \n",
    "#Apprentissage\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_AD_MCI_selection1, [0]*28+[1]*22, test_size=0.33, random_state=0)\n",
    "svm_mod = svm.SVC()\n",
    "svm_fit = svm_mod.fit(X_train,y_train)\n",
    "svm_predictions = svm_fit.predict(X_test)\n",
    "\n",
    "\n",
    "#Accuaracy score:\n",
    "score = sklearn.metrics.accuracy_score(y_test, svm_predictions)\n",
    "print('Score accuaracy for SVM =',score)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
