{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice 1: regression logistique avec keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(len(y_test))\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0109 10:20:11.297035 4639815104 deprecation_wrapper.py:119] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Creation d'un reseau de neurones vide\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0109 10:20:12.654258 4639815104 deprecation_wrapper.py:119] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0109 10:20:12.676559 4639815104 deprecation_wrapper.py:119] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Ajout d'une couche cachée et d'une fonction d'activation\n",
    "model.add(Dense(10,input_dim = 784,name = 'fc1'))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "fc1 (Dense)                  (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Visualisation de l'architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0109 10:20:15.323123 4639815104 deprecation_wrapper.py:119] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0109 10:20:15.354354 4639815104 deprecation_wrapper.py:119] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#compilation avec une foction loss\n",
    "learning_rate = 0.1\n",
    "sgd = SGD(learning_rate)\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n",
      "W0101 20:17:11.844472 4641408448 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0101 20:17:11.894359 4641408448 deprecation_wrapper.py:119] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 1.1782 - acc: 0.7242\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.6478 - acc: 0.8518\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.5388 - acc: 0.8669\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.4867 - acc: 0.8755\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.4547 - acc: 0.8812\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.4327 - acc: 0.8851\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.4164 - acc: 0.8884\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.4035 - acc: 0.8914\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.3932 - acc: 0.8936\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3846 - acc: 0.8953\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.3773 - acc: 0.8970\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3710 - acc: 0.8987\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 0.3654 - acc: 0.8994\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3605 - acc: 0.9007\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3562 - acc: 0.9019\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3523 - acc: 0.9026\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3486 - acc: 0.9037\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3453 - acc: 0.9045\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3424 - acc: 0.9048\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3396 - acc: 0.9056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x135026400>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Phase d'apprentissage (fit)\n",
    "batch_size = 100\n",
    "nb_epoch = 20\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train,10)\n",
    "Y_test = np_utils.to_categorical(y_test,10)\n",
    "\n",
    "model.fit(X_train,Y_train,batch_size = batch_size,nb_epoch = nb_epoch,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9e5d8f37d5ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Evaluer les performances du modèle dur l'ensemble de test:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Print de la fonction cout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s: %.2f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Y_test' is not defined"
     ]
    }
   ],
   "source": [
    "#Evaluer les performances du modèle dur l'ensemble de test:\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "#Print de la fonction cout\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[0], scores[0]*100))\n",
    "\n",
    "#print de l'accuracy\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice2: Perceptron avec keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation d'un reseau de neurones vide\n",
    "model2 = Sequential()\n",
    "\n",
    "#Ajout d'une couche cachée et d'une fonction d'activation\n",
    "model2.add(Dense(100,  input_dim=784, name='fc1'))\n",
    "model2.add(Activation('sigmoid'))\n",
    "model2.add(Dense(10))\n",
    "model2.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "fc1 (Dense)                  (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compilation avec une foction loss\n",
    "learning_rate = 1.0\n",
    "sgd = SGD(learning_rate)\n",
    "\n",
    "model2.compile(loss = 'categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 2s 25us/step - loss: 1.9539 - acc: 0.5483\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 1.3897 - acc: 0.7562\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 1.0401 - acc: 0.8048\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.8410 - acc: 0.8307\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.7205 - acc: 0.8452\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.6411 - acc: 0.8554\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.5850 - acc: 0.8637\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.5431 - acc: 0.8701\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 0.5107 - acc: 0.8751\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.4846 - acc: 0.8789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x140d19c18>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Phase d'apprentissage (fit)\n",
    "batch_size = 100\n",
    "nb_epoch = 10 #faut changer en 100 pour plus d 'accuracy'\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train,10)\n",
    "Y_test = np_utils.to_categorical(y_test,10)\n",
    "\n",
    "model2.fit(X_train,Y_train,batch_size = batch_size,nb_epoch = nb_epoch,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 45.26%\n",
      "acc: 89.08%\n"
     ]
    }
   ],
   "source": [
    "#Evaluer les performances du modèle dur l'ensemble de test:\n",
    "scores = model2.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "#Print de la fonction cout\n",
    "print(\"%s: %.2f%%\" % (model2.metrics_names[0], scores[0]*100))\n",
    "\n",
    "#print de l'accuracy\n",
    "print(\"%s: %.2f%%\" % (model2.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yaml Model  perceptron keras .yaml saved to disk\n",
      "Weights  perceptron keras .h5 saved to disk\n"
     ]
    }
   ],
   "source": [
    "#Suvegarder le modèle\n",
    "from keras.models import model_from_yaml\n",
    "def saveModel(model, savename):\n",
    "  # serialize model to YAML\n",
    "    model_yaml = model.to_yaml()\n",
    "    with open(savename+\".yaml\", \"w\") as yaml_file:\n",
    "        yaml_file.write(model_yaml)\n",
    "    print(\"Yaml Model \",savename,\".yaml saved to disk\")\n",
    "      # serialize weights to HDF5\n",
    "    model.save_weights(savename+\".h5\")\n",
    "    print(\"Weights \",savename,\".h5 saved to disk\")\n",
    "\n",
    "saveModel(model2,'perceptron keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice3: Reseau de neurones convolutifavec keras: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementation d'un ConvNet\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1230 15:33:09.448413 4590716352 deprecation_wrapper.py:119] From /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Convolution\n",
    "model3.add(Conv2D(16,kernel_size=(5, 5),activation='relu',input_shape=(28, 28, 1),padding='valid'))\n",
    "#Max-pooling avec un décalage de 2(par défaut)\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model3.add(Conv2D(32,kernel_size=(5, 5),activation='relu',input_shape=(28, 28, 1),padding='valid'))\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#Flatten\n",
    "model3.add(Flatten())\n",
    "\n",
    "#Ajout de couche completement connectées:\n",
    "model3.add(Dense(100))\n",
    "model3.add(Activation('sigmoid'))\n",
    "model3.add(Dense(10))\n",
    "model3.add(Activation('softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:14: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 33s 552us/step - loss: 2.0240 - acc: 0.4429\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 28s 472us/step - loss: 0.7297 - acc: 0.8475\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 29s 483us/step - loss: 0.4188 - acc: 0.8977\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 28s 462us/step - loss: 0.3211 - acc: 0.9180\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 28s 464us/step - loss: 0.2665 - acc: 0.9306\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 28s 471us/step - loss: 0.2301 - acc: 0.9389\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 26s 435us/step - loss: 0.2035 - acc: 0.9460\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 40s 665us/step - loss: 0.1831 - acc: 0.9516\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 32s 531us/step - loss: 0.1668 - acc: 0.9555\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 28s 461us/step - loss: 0.1536 - acc: 0.9592\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 28s 460us/step - loss: 0.1430 - acc: 0.9614\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 28s 465us/step - loss: 0.1337 - acc: 0.9641\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 28s 474us/step - loss: 0.1258 - acc: 0.9661\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.1191 - acc: 0.9679\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 497s 8ms/step - loss: 0.1133 - acc: 0.9693\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 29s 485us/step - loss: 0.1079 - acc: 0.9704\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 27s 445us/step - loss: 0.1034 - acc: 0.9722\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 26s 436us/step - loss: 0.0989 - acc: 0.9730\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 30s 505us/step - loss: 0.0954 - acc: 0.9738\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 28s 460us/step - loss: 0.0917 - acc: 0.9746\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 27s 449us/step - loss: 0.0887 - acc: 0.9757\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 28s 461us/step - loss: 0.0857 - acc: 0.9769\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 26s 441us/step - loss: 0.0832 - acc: 0.9772\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 27s 448us/step - loss: 0.0804 - acc: 0.9779\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 28s 465us/step - loss: 0.0786 - acc: 0.9784\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 30s 505us/step - loss: 0.0761 - acc: 0.9790\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 31s 511us/step - loss: 0.0742 - acc: 0.9796\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 28s 472us/step - loss: 0.0723 - acc: 0.9800\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 0.0704 - acc: 0.9807\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 27s 450us/step - loss: 0.0689 - acc: 0.9812\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 26s 431us/step - loss: 0.0672 - acc: 0.9814\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 31s 513us/step - loss: 0.0657 - acc: 0.9819\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 31s 514us/step - loss: 0.0644 - acc: 0.9825\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 25s 420us/step - loss: 0.0631 - acc: 0.9828\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 25s 420us/step - loss: 0.0618 - acc: 0.9829\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 25s 420us/step - loss: 0.0605 - acc: 0.9833\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 26s 427us/step - loss: 0.0594 - acc: 0.9836\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 26s 435us/step - loss: 0.0583 - acc: 0.9840\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 26s 441us/step - loss: 0.0572 - acc: 0.9840\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 27s 451us/step - loss: 0.0562 - acc: 0.9844\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 27s 446us/step - loss: 0.0553 - acc: 0.9853\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 27s 443us/step - loss: 0.0544 - acc: 0.9851\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 27s 444us/step - loss: 0.0535 - acc: 0.9853\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 27s 450us/step - loss: 0.0525 - acc: 0.9852\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 28s 462us/step - loss: 0.0518 - acc: 0.9859\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 27s 453us/step - loss: 0.0511 - acc: 0.9860\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 27s 456us/step - loss: 0.0501 - acc: 0.9863\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 28s 466us/step - loss: 0.0494 - acc: 0.9862\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 27s 453us/step - loss: 0.0486 - acc: 0.9865\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 29s 479us/step - loss: 0.0478 - acc: 0.9868\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 27s 449us/step - loss: 0.0474 - acc: 0.9872\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 27s 447us/step - loss: 0.0466 - acc: 0.9871\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 26s 436us/step - loss: 0.0461 - acc: 0.9876\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 26s 436us/step - loss: 0.0454 - acc: 0.9873\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 27s 455us/step - loss: 0.0448 - acc: 0.9877\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 26s 439us/step - loss: 0.0442 - acc: 0.9882\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 26s 434us/step - loss: 0.0434 - acc: 0.9883\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 2133s 36ms/step - loss: 0.0429 - acc: 0.9887\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 25s 424us/step - loss: 0.0424 - acc: 0.9886\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 1885s 31ms/step - loss: 0.0421 - acc: 0.9887\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 26s 436us/step - loss: 0.0415 - acc: 0.9885\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 29s 490us/step - loss: 0.0410 - acc: 0.9890\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 33s 549us/step - loss: 0.0403 - acc: 0.9893\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 34s 567us/step - loss: 0.0400 - acc: 0.9893\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 35s 582us/step - loss: 0.0394 - acc: 0.9895\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 36s 602us/step - loss: 0.0389 - acc: 0.9895\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 36s 605us/step - loss: 0.0385 - acc: 0.9896\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 37s 611us/step - loss: 0.0379 - acc: 0.9901\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 38s 629us/step - loss: 0.0377 - acc: 0.9902\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 38s 627us/step - loss: 0.0370 - acc: 0.9903\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 38s 631us/step - loss: 0.0368 - acc: 0.9902\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 38s 629us/step - loss: 0.0364 - acc: 0.9904\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 38s 641us/step - loss: 0.0359 - acc: 0.9907\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 38s 635us/step - loss: 0.0355 - acc: 0.9910\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 38s 639us/step - loss: 0.0351 - acc: 0.9911\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 38s 636us/step - loss: 0.0347 - acc: 0.9908\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 39s 655us/step - loss: 0.0343 - acc: 0.9911\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 38s 641us/step - loss: 0.0341 - acc: 0.9912\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 39s 651us/step - loss: 0.0336 - acc: 0.9913\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 39s 647us/step - loss: 0.0332 - acc: 0.9914\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 36s 602us/step - loss: 0.0328 - acc: 0.9918\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 37s 615us/step - loss: 0.0325 - acc: 0.9917\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 27s 447us/step - loss: 0.0322 - acc: 0.9918\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 26s 425us/step - loss: 0.0319 - acc: 0.9923\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 28s 471us/step - loss: 0.0315 - acc: 0.9921\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 29s 482us/step - loss: 0.0312 - acc: 0.9922\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 27s 454us/step - loss: 0.0309 - acc: 0.9923\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 27s 456us/step - loss: 0.0305 - acc: 0.9923\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 27s 448us/step - loss: 0.0303 - acc: 0.9925\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 27s 450us/step - loss: 0.0299 - acc: 0.9927\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 27s 455us/step - loss: 0.0297 - acc: 0.9927\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 25s 409us/step - loss: 0.0294 - acc: 0.9927\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 25s 419us/step - loss: 0.0290 - acc: 0.9933\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 24s 408us/step - loss: 0.0287 - acc: 0.9930\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 37s 609us/step - loss: 0.0285 - acc: 0.9931\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 27s 453us/step - loss: 0.0281 - acc: 0.9932\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 25s 417us/step - loss: 0.0279 - acc: 0.9933\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 25s 409us/step - loss: 0.0275 - acc: 0.9934\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 25s 419us/step - loss: 0.0273 - acc: 0.9934\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 27s 448us/step - loss: 0.0271 - acc: 0.9937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x141b80f28>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compilation avec une foction loss\n",
    "learning_rate = 1.0\n",
    "sgd = SGD(learning_rate)\n",
    "\n",
    "model3.compile(loss = 'categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])\n",
    "\n",
    "#Phase d'apprentissage (fit)\n",
    "batch_size = 100\n",
    "nb_epoch = 100\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train,10)\n",
    "Y_test = np_utils.to_categorical(y_test,10)\n",
    "\n",
    "model3.fit(X_train,Y_train,batch_size = batch_size,nb_epoch = nb_epoch,verbose = 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 3.73%\n",
      "acc: 98.90%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Evaluer les performances du modèle dur l'ensemble de test:\n",
    "scores = model3.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "#Print de la fonction cout\n",
    "print(\"%s: %.2f%%\" % (model3.metrics_names[0], scores[0]*100))\n",
    "\n",
    "#print de l'accuracy\n",
    "print(\"%s: %.2f%%\" % (model3.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercice 4: Visualition avec t-SNE: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.use('TKAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "from scipy.spatial import ConvexHull\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy import linalg\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "instance = TSNE(n_components=2,init='pca',perplexity=30,verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 500 samples in 0.013s...\n",
      "[t-SNE] Computed neighbors for 500 samples in 0.326s...\n",
      "[t-SNE] Computed conditional probabilities for sample 500 / 500\n",
      "[t-SNE] Mean sigma: 2.991658\n",
      "[t-SNE] Computed conditional probabilities in 0.028s\n",
      "[t-SNE] Iteration 50: error = 68.1388474, gradient norm = 0.5004482 (50 iterations in 0.212s)\n",
      "[t-SNE] Iteration 100: error = 68.5918961, gradient norm = 0.5084785 (50 iterations in 0.186s)\n",
      "[t-SNE] Iteration 150: error = 70.2480087, gradient norm = 0.4795871 (50 iterations in 0.181s)\n",
      "[t-SNE] Iteration 200: error = 70.2602539, gradient norm = 0.4867442 (50 iterations in 0.203s)\n",
      "[t-SNE] Iteration 250: error = 69.5945282, gradient norm = 0.4897161 (50 iterations in 0.203s)\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 69.594528\n",
      "[t-SNE] Iteration 300: error = 0.9218195, gradient norm = 0.0030550 (50 iterations in 0.131s)\n",
      "[t-SNE] Iteration 350: error = 0.8192357, gradient norm = 0.0009033 (50 iterations in 0.129s)\n",
      "[t-SNE] Iteration 400: error = 0.7863802, gradient norm = 0.0005213 (50 iterations in 0.179s)\n",
      "[t-SNE] Iteration 450: error = 0.7679008, gradient norm = 0.0005532 (50 iterations in 0.189s)\n",
      "[t-SNE] Iteration 500: error = 0.7410420, gradient norm = 0.0013028 (50 iterations in 0.125s)\n",
      "[t-SNE] Iteration 550: error = 0.7345333, gradient norm = 0.0002784 (50 iterations in 0.136s)\n",
      "[t-SNE] Iteration 600: error = 0.7320654, gradient norm = 0.0001526 (50 iterations in 0.122s)\n",
      "[t-SNE] Iteration 650: error = 0.7298126, gradient norm = 0.0002061 (50 iterations in 0.129s)\n",
      "[t-SNE] Iteration 700: error = 0.7243595, gradient norm = 0.0003927 (50 iterations in 0.118s)\n",
      "[t-SNE] Iteration 750: error = 0.7190099, gradient norm = 0.0003144 (50 iterations in 0.123s)\n",
      "[t-SNE] Iteration 800: error = 0.7179536, gradient norm = 0.0002349 (50 iterations in 0.114s)\n",
      "[t-SNE] Iteration 850: error = 0.7168783, gradient norm = 0.0002497 (50 iterations in 0.123s)\n",
      "[t-SNE] Iteration 900: error = 0.7162072, gradient norm = 0.0001891 (50 iterations in 0.118s)\n",
      "[t-SNE] Iteration 950: error = 0.7153325, gradient norm = 0.0001468 (50 iterations in 0.121s)\n",
      "[t-SNE] Iteration 1000: error = 0.7145162, gradient norm = 0.0001817 (50 iterations in 0.117s)\n",
      "[t-SNE] KL divergence after 1000 iterations: 0.714516\n"
     ]
    }
   ],
   "source": [
    "x2d = instance.fit_transform(X_train[:500,:])\n",
    "labels = y_train[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x2d' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-df7842832e20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconvex_hulls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Function Call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mconvex_hulls\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mconvexHulls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x2d' is not defined"
     ]
    }
   ],
   "source": [
    "#Calcul de l’enveloppe convexe des points projetés pour chacune des classe classe.\n",
    "def convexHulls(points, labels):\n",
    "    convex_hulls = []\n",
    "    for i in range(10):\n",
    "        convex_hulls.append(ConvexHull(points[labels==i,:]))\n",
    "    return convex_hulls\n",
    "# Function Call\n",
    "convex_hulls= convexHulls(x2d, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcul de l’ellipse de meilleure approximation des points.\n",
    "def best_ellipses(points, labels):\n",
    "    gaussians = []\n",
    "    for i in range(10):\n",
    "        gaussians.append(GaussianMixture(n_components=1, covariance_type='full').fit(points[labels==i, :]))\n",
    "    return gaussians\n",
    "# Function Call\n",
    "ellipses = best_ellipses(x2d, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calcul du « Neighborhood Hit » (NH) \n",
    "def neighboring_hit(points, labels):\n",
    "    k = 6\n",
    "    nbrs = NearestNeighbors(n_neighbors=k+1, algorithm='ball_tree').fit(points)\n",
    "    distances, indices = nbrs.kneighbors(points)\n",
    "\n",
    "    txs = 0.0\n",
    "    txsc = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    nppts = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "\n",
    "    for i in range(len(points)):\n",
    "        tx = 0.0\n",
    "    for j in range(1,k+1):\n",
    "        if (labels[indices[i,j]]== labels[i]):\n",
    "            tx += 1\n",
    "    tx /= k\n",
    "    txsc[labels[i]] += tx\n",
    "    nppts[labels[i]] += 1\n",
    "    txs += tx\n",
    "\n",
    "    for i in range(10):\n",
    "        txsc[i] /= nppts[i]\n",
    "\n",
    "    return txs / len(points)\n",
    "    return txs / len(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualization(points2D, labels, convex_hulls, ellipses ,projname, nh):\n",
    "    points2D_c= []\n",
    "    for i in range(10):\n",
    "          points2D_c.append(points2D[labels==i, :])\n",
    "    # Data Visualization\n",
    "    cmap =cm.tab10\n",
    "\n",
    "    plt.figure(figsize=(3.841, 7.195), dpi=100)\n",
    "    plt.set_cmap(cmap)\n",
    "    plt.subplots_adjust(hspace=0.4 )\n",
    "    plt.subplot(311)\n",
    "    plt.scatter(points2D[:,0], points2D[:,1], c=labels,  s=3,edgecolors='none', cmap=cmap, alpha=1.0)\n",
    "    plt.colorbar(ticks=range(10))\n",
    "\n",
    "    plt.title(\"2D \"+projname+\" - NH=\"+str(nh*100.0))\n",
    "\n",
    "    vals = [ i/10.0 for i in range(10)]\n",
    "    sp2 = plt.subplot(312)\n",
    "    for i in range(10):\n",
    "        ch = np.append(convex_hulls[i].vertices,convex_hulls[i].vertices[0])\n",
    "        sp2.plot(points2D_c[i][ch, 0], points2D_c[i][ch, 1], '-',label='$%i$'%i, color=cmap(vals[i]))\n",
    "    plt.colorbar(ticks=range(10))\n",
    "    plt.title(projname+\" Convex Hulls\")\n",
    "    \n",
    "\n",
    "    def plot_results(X, Y_, means, covariances, index, title, color):\n",
    "        splot = plt.subplot(3, 1, 3)\n",
    "        for i, (mean, covar) in enumerate(zip(means, covariances)):\n",
    "            v, w = linalg.eigh(covar)\n",
    "            v = 2. * np.sqrt(2.) * np.sqrt(v)\n",
    "            u = w[0] / linalg.norm(w[0])\n",
    "          # as the DP will not use every component it has access to\n",
    "          # unless it needs it, we shouldn't plot the redundant\n",
    "          # components.\n",
    "            if not np.any(Y_ == i):\n",
    "                  continue\n",
    "            plt.scatter(X[Y_ == i, 0], X[Y_ == i, 1], .8, color=color, alpha = 0.2)\n",
    "\n",
    "          # Plot an ellipse to show the Gaussian component\n",
    "            angle = np.arctan(u[1] / u[0])\n",
    "            angle = 180. * angle / np.pi  # convert to degrees\n",
    "            ell = mpl.patches.Ellipse(mean, v[0], v[1], 180. + angle, color=color)\n",
    "            ell.set_clip_box(splot.bbox)\n",
    "            ell.set_alpha(0.6)\n",
    "            splot.add_artist(ell)\n",
    "\n",
    "        plt.title(title)\n",
    "    plt.subplot(313)\n",
    "\n",
    "    for i in range(10):\n",
    "        plot_results(points2D[labels==i, :], ellipses[i].predict(points2D[labels==i, :]), ellipses[i].means_,\n",
    "        ellipses[i].covariances_, 0,projname+\" fitting ellipses\", cmap(vals[i]))\n",
    "\n",
    "    plt.savefig(projname+\".png\", dpi=100)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:27: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:27: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:27: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:27: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:27: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:27: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:27: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:27: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:27: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:27: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-d7f4d32ca4e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvisualization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconvex_hulls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mellipses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'proj1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-0ea6c5e0ed30>\u001b[0m in \u001b[0;36mvisualization\u001b[0;34m(points2D, labels, convex_hulls, ellipses, projname, nh)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprojname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \"\"\"\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0;34m\"parameter will become keyword-only %(removal)s.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m                 name=name, obj_type=f\"parameter of {func.__name__}()\")\n\u001b[0;32m--> 413\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(cls, block)\u001b[0m\n\u001b[1;32m   3300\u001b[0m                 \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3301\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3302\u001b[0;31m             \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3304\u001b[0m     \u001b[0;31m# This method is the one actually exporting the required methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/matplotlib/backends/_backend_tk.py\u001b[0m in \u001b[0;36mmainloop\u001b[0;34m()\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0mmanagers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_fig_managers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmanagers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m             \u001b[0mmanagers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/tkinter/__init__.py\u001b[0m in \u001b[0;36mmainloop\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m   1281\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m         \u001b[0;34m\"\"\"Call the mainloop of Tk.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1283\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mquit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m         \u001b[0;34m\"\"\"Quit the Tcl interpreter. All widgets will be destroyed.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "visualization(x2d,labels,convex_hulls,ellipses,'proj1',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_yaml\n",
    "def loadModel(savename):\n",
    "    with open(savename+\".yaml\", \"r\") as yaml_file:\n",
    "        model = model_from_yaml(yaml_file.read())\n",
    "    print (\"Yaml Model \",savename,\".yaml loaded \")\n",
    "    model.load_weights(savename+\".h5\")\n",
    "    print (\"Weights \",savename,\".h5 loaded \")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/keras/engine/saving.py:473: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  config = yaml.load(yaml_string)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yaml Model  perceptron keras .yaml loaded \n",
      "Weights  perceptron keras .h5 loaded \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.36009127, -1.8992574 , -0.9515605 , ...,  6.753829  ,\n",
       "        -1.0620937 ,  2.6189773 ],\n",
       "       [ 1.8351802 , -0.66558063,  4.0233765 , ..., -4.1836104 ,\n",
       "         1.2421086 , -3.9751565 ],\n",
       "       [-3.0118618 ,  4.6853294 ,  0.9796171 , ...,  0.36727896,\n",
       "         0.35360274, -0.77612054],\n",
       "       ...,\n",
       "       [-3.4988132 , -1.8804232 , -1.9919015 , ...,  1.30428   ,\n",
       "         1.9327623 ,  3.6159534 ],\n",
       "       [-0.19217472, -0.03861643, -1.1462921 , ..., -1.0209585 ,\n",
       "         2.3887    , -1.0414436 ],\n",
       "       [ 3.1047585 , -2.702783  ,  2.9928942 , ..., -3.6471167 ,\n",
       "        -0.21771246, -1.7189764 ]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = loadModel('perceptron keras')\n",
    "model.pop()\n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_bis = TSNE(n_components=2,init='pca',perplexity=30,verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 91 nearest neighbors...\n",
      "[t-SNE] Indexed 500 samples in 0.007s...\n",
      "[t-SNE] Computed neighbors for 500 samples in 0.308s...\n",
      "[t-SNE] Computed conditional probabilities for sample 500 / 500\n",
      "[t-SNE] Mean sigma: 2.991658\n",
      "[t-SNE] Computed conditional probabilities in 0.017s\n",
      "[t-SNE] Iteration 50: error = 67.6867828, gradient norm = 0.5064182 (50 iterations in 0.197s)\n",
      "[t-SNE] Iteration 100: error = 68.4462509, gradient norm = 0.5007352 (50 iterations in 0.181s)\n",
      "[t-SNE] Iteration 150: error = 68.3040009, gradient norm = 0.5125185 (50 iterations in 0.179s)\n",
      "[t-SNE] Iteration 200: error = 68.9822693, gradient norm = 0.4919740 (50 iterations in 0.186s)\n",
      "[t-SNE] Iteration 250: error = 70.1537476, gradient norm = 0.4809603 (50 iterations in 0.186s)\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 70.153748\n",
      "[t-SNE] Iteration 300: error = 0.9411983, gradient norm = 0.0035173 (50 iterations in 0.134s)\n",
      "[t-SNE] Iteration 350: error = 0.8798773, gradient norm = 0.0010811 (50 iterations in 0.134s)\n",
      "[t-SNE] Iteration 400: error = 0.8537772, gradient norm = 0.0006805 (50 iterations in 0.125s)\n",
      "[t-SNE] Iteration 450: error = 0.8333651, gradient norm = 0.0005896 (50 iterations in 0.135s)\n",
      "[t-SNE] Iteration 500: error = 0.8281063, gradient norm = 0.0003620 (50 iterations in 0.126s)\n",
      "[t-SNE] Iteration 550: error = 0.8237255, gradient norm = 0.0003313 (50 iterations in 0.135s)\n",
      "[t-SNE] Iteration 600: error = 0.7943718, gradient norm = 0.0006351 (50 iterations in 0.129s)\n",
      "[t-SNE] Iteration 650: error = 0.7857736, gradient norm = 0.0001899 (50 iterations in 0.141s)\n",
      "[t-SNE] Iteration 700: error = 0.7837901, gradient norm = 0.0001777 (50 iterations in 0.131s)\n",
      "[t-SNE] Iteration 750: error = 0.7825071, gradient norm = 0.0001158 (50 iterations in 0.140s)\n",
      "[t-SNE] Iteration 800: error = 0.7818839, gradient norm = 0.0001448 (50 iterations in 0.148s)\n",
      "[t-SNE] Iteration 850: error = 0.7752143, gradient norm = 0.0003755 (50 iterations in 0.208s)\n",
      "[t-SNE] Iteration 900: error = 0.7611458, gradient norm = 0.0006598 (50 iterations in 0.167s)\n",
      "[t-SNE] Iteration 950: error = 0.7599978, gradient norm = 0.0001117 (50 iterations in 0.200s)\n",
      "[t-SNE] Iteration 1000: error = 0.7568370, gradient norm = 0.0001390 (50 iterations in 0.146s)\n",
      "[t-SNE] KL divergence after 1000 iterations: 0.756837\n"
     ]
    }
   ],
   "source": [
    "x2d_bis = instance_bis.fit_transform(X_train[:500,:])\n",
    "labels = y_train[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'convexHulls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-94bdc1b09778>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconvex_hulls\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mconvexHulls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2d_bis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mellipses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_ellipses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2d_bis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvisualization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconvex_hulls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mellipses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'proj2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'convexHulls' is not defined"
     ]
    }
   ],
   "source": [
    "convex_hulls= convexHulls(x2d_bis, labels)\n",
    "ellipses = best_ellipses(x2d_bis, labels)\n",
    "visualization(x2d,labels,convex_hulls,ellipses,'proj2',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
